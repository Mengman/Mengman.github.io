<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-01-04T22:59:54+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Mengman的异想世界</title><subtitle>Program 4 Fun/n Program 4 Life</subtitle><entry><title type="html">CUDA 代码编译流程</title><link href="http://localhost:4000/matchinelearning/deeplearning/softwareenginer/cuda/2024/01/04/CUDA-compiler.html" rel="alternate" type="text/html" title="CUDA 代码编译流程" /><published>2024-01-04T00:00:00+08:00</published><updated>2024-01-04T00:00:00+08:00</updated><id>http://localhost:4000/matchinelearning/deeplearning/softwareenginer/cuda/2024/01/04/CUDA-compiler</id><content type="html" xml:base="http://localhost:4000/matchinelearning/deeplearning/softwareenginer/cuda/2024/01/04/CUDA-compiler.html"><![CDATA[<h1 id="1-编译流程">1 编译流程</h1>

<p>随着 Nvidia 不断更新 GPU 硬件设计架构，每一代架构更迭都会引入新的功能，在同一代架构中不同的 GPU 型号在硬件配置上与性能上也会有一些细小的差异。</p>

<p>Nvidia 提供了一套代号来标识 GPU 的<strong>真实架构</strong>，它的格式是 <code class="language-plaintext highlighter-rouge">sm_xy</code>，<code class="language-plaintext highlighter-rouge">x</code> 代表 GPU 架构世代的编号，<code class="language-plaintext highlighter-rouge">y</code>代表 GPU 在这个架构世代中的版本号。为了方便对比 GPU 能力，如果 <code class="language-plaintext highlighter-rouge">x1y1 &lt;= x2y2</code> 那么<code class="language-plaintext highlighter-rouge">sm_x1y1</code>中所有非 ISA 相关的功能都包含在 <code class="language-plaintext highlighter-rouge">sm_x2y2</code> 中了。</p>

<p>然而这并不能保证新的 GPU 架构就能兼容老的 GPU 架构的二进制代码，比如在 Fermi 架构上编译的代码就无法在Kepler GPU 上运行，因为它们的指令集与指令编码都是不一样的。只用在相同的架构下才能保持二进制兼容。为了解决这个问题，CUDA 代码采用了两阶段编译过程。</p>

<p><strong>第一个阶段</strong></p>

<p>nvcc 编译器将 CUDA 代码编译成 PTX 代码，这是一种类似汇编的代码。它基于<strong>虚拟架构</strong>进行编译，虚拟架构是根据 GPU 能力、功能来定义的。</p>

<p><strong>第二个阶段</strong></p>

<p>nvcc 编译器是包含在 GPU 驱动中，编译器可以预先或者在运行的时候根据<strong>真实架构</strong>将 PTX 代码编译成实际的二进制代码。</p>

<p>第一个阶段的<strong>虚拟架构</strong>要兼容第二个阶段的<strong>真实架构</strong>，<strong>虚拟架构</strong>的版本越低就越能兼容更多的<strong>真实架构</strong>，当然CUDA 代码支持的功能也就越少。</p>

<p><img src="/assets/virtual-architectures.png" alt="Two-Staged Compilation with Virtual and Real Architectures" /></p>

<p>对于在 CPU 上运行的 host code 与 GPU 上运行的 device code，编译器会分开进行编译。</p>

<ol>
  <li>nvcc 会将 device code (kernel 函数) 编译成 PTX code 或者二进制格式 (cubin object) 。</li>
  <li>nvcc 会修改 host code 中调用 kernel 的部分，修改为 PTX code 或者 cubin object 中实际的代码。</li>
</ol>

<p><strong>架构代号列表</strong></p>

<table>
  <thead>
    <tr>
      <th>虚拟架构代号</th>
      <th>真实架构代号</th>
      <th>CUDA支持版本</th>
      <th>支持架构</th>
      <th>支持硬件</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>compute_50</td>
      <td>sm_50</td>
      <td>CUDA 6~11</td>
      <td>Maxwell</td>
      <td>Tesla/Quadro M series</td>
    </tr>
    <tr>
      <td>compute_52</td>
      <td>sm_52</td>
      <td>CUDA 6~11</td>
      <td>Maxwell</td>
      <td>GTX-980, GTX Titan X</td>
    </tr>
    <tr>
      <td>compute_53</td>
      <td>sm_53</td>
      <td>CUDA 6~11</td>
      <td>Maxwell</td>
      <td>Tegra TX1, Jetson Nano</td>
    </tr>
    <tr>
      <td>compute_60</td>
      <td>sm_60</td>
      <td>CUDA 8</td>
      <td>Pascal</td>
      <td>Tesla P100</td>
    </tr>
    <tr>
      <td>compute_61</td>
      <td>sm_61</td>
      <td>CUDA 8</td>
      <td>Pascal</td>
      <td>GTX 1080, GTX1070</td>
    </tr>
    <tr>
      <td>compute_62</td>
      <td>sm_62</td>
      <td>CUDA 8</td>
      <td>Pascal</td>
      <td>Jetson TX2</td>
    </tr>
    <tr>
      <td>compute_70</td>
      <td>sm_70</td>
      <td>CUDA 9</td>
      <td>Volta</td>
      <td>Tesla V100</td>
    </tr>
    <tr>
      <td>compute_72</td>
      <td>sm_72</td>
      <td>CUDA 9</td>
      <td>Volta</td>
      <td>Jetson AGX Xavier</td>
    </tr>
    <tr>
      <td>compute_75</td>
      <td>sm_75</td>
      <td>CUDA 10</td>
      <td>Turing</td>
      <td>RTX 2080, RTX 2070 Tesla T4</td>
    </tr>
    <tr>
      <td>compute_80</td>
      <td>sm_80</td>
      <td>CUDA 11.1</td>
      <td>Ampere</td>
      <td>A100</td>
    </tr>
    <tr>
      <td>compute_86</td>
      <td>sm_86</td>
      <td>CUDA 11.1</td>
      <td>Ampere</td>
      <td>RTX 3090</td>
    </tr>
    <tr>
      <td>compute_87</td>
      <td>sm_87</td>
      <td>CUDA 11.1</td>
      <td>Ampere</td>
      <td>Jetson AGX Orin</td>
    </tr>
    <tr>
      <td>compute_89</td>
      <td>sm_89</td>
      <td>CUDA 11.8</td>
      <td>Lovelace</td>
      <td>RTX 4090</td>
    </tr>
    <tr>
      <td>compute_90</td>
      <td>sm_90</td>
      <td>CUDA 12</td>
      <td>Hopper</td>
      <td>H100 H200</td>
    </tr>
    <tr>
      <td>compute_95</td>
      <td>sm_95</td>
      <td>CUDA 12</td>
      <td>Blackwell</td>
      <td>B100</td>
    </tr>
  </tbody>
</table>

<h1 id="2-ptx">2 PTX</h1>

<p>上一节提到的 <strong>PTX</strong> (Parallel Thread Execution) 是 Nvidia 为 CUDA 设计的一种低级虚拟机和指令架构，它是CUDA 代码的中间表示形式，有以下特征：</p>

<ol>
  <li>由虚拟指令集定义：用一套虚拟的并行指令集，用于表示 CUDA 设备功能。</li>
  <li>目标独立：采用抽象的寄存器和线程模型，不依赖于具体的 GPU 架构，可以针对不同的 GPU 生成优化机器代码。</li>
  <li>可移植： PTX 代码可以在不同的 CUDA 运行环境和 GPU设备上执行。</li>
  <li>JIT 编译： PTX 代码在执行前，有 GPU 驱动编译生成针对特定 GPU 的机器代码。</li>
  <li>可读性好：PTX 代码结构类似汇编，以文本形式保存，便于阅读和调试。</li>
  <li>虚拟寻址：提供了统一的虚拟寄存器和寻址空间</li>
</ol>

<h1 id="3-jit-编译">3 JIT 编译</h1>

<p>PTX 代码在目标机器上执行前，会由 GPU 驱动将 PTX 代码优化、编译为机器代码。PTX 代码的编译结果会被缓存下来，以免重复编译。但是如果更新了 GPU 驱动，那么 PTX 代码会重新编译。</p>

<p><strong>在不同操作系统下 JIT 缓存目录</strong></p>

<table>
  <thead>
    <tr>
      <th>操作系统</th>
      <th>缓存目录</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Linux</td>
      <td><code class="language-plaintext highlighter-rouge">~/.nv/ComputeCache</code></td>
    </tr>
    <tr>
      <td>Windows</td>
      <td><code class="language-plaintext highlighter-rouge">%APPDATA\%NVIDIA\ComputeCache</code></td>
    </tr>
    <tr>
      <td>MacOS</td>
      <td><code class="language-plaintext highlighter-rouge">$HOME/Library/Application Support/NVIDIA/ComputeCache</code></td>
    </tr>
  </tbody>
</table>

<p><strong>与 JIT 相关的环境变量配置</strong></p>

<table>
  <thead>
    <tr>
      <th>环境变量</th>
      <th>默认值</th>
      <th>说明</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">CUDA_CACHE_DISABLE</code></td>
      <td>0</td>
      <td>是否禁用 JIT cache，<code class="language-plaintext highlighter-rouge">1</code> 代表禁用 <code class="language-plaintext highlighter-rouge">0</code> 代表不禁用</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">CUDA_CACHE_MAXSIZE</code></td>
      <td>256MB</td>
      <td>cache 的尺寸，最大值 4GB， 在 334 版本驱动前，默认值是 32MB</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">CUDA_CACHE_PATH</code></td>
      <td>略</td>
      <td>设置 cache 目录</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">CUDA_FORECE_PTX_JIT</code></td>
      <td>0</td>
      <td>设置为 <code class="language-plaintext highlighter-rouge">1</code> 时，强制忽略预编译好的机器代码，使用 JIT 从 PTX 代码中编译出机器代码</td>
    </tr>
  </tbody>
</table>

<h1 id="4-编译参数-arch--code">4 编译参数 arch &amp; code</h1>

<p><code class="language-plaintext highlighter-rouge">nvcc</code> 编译器在编译 CDUA 代码的时候提供了 <code class="language-plaintext highlighter-rouge">-gencode</code> 参数，这个参数接收 <code class="language-plaintext highlighter-rouge">arch=compute_xx</code> 与 <code class="language-plaintext highlighter-rouge">code=sm_xx</code> 作为参数。也可以单独使用 <code class="language-plaintext highlighter-rouge">-arch</code> 和 <code class="language-plaintext highlighter-rouge">-code</code> 来指定。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nvcc x.cu <span class="nt">-gencode</span> <span class="nb">arch</span><span class="o">=</span>compute_50,code<span class="o">=</span>sm_50
</code></pre></div></div>

<h2 id="gpu-architecture-arch">–gpu-architecture(-arch)</h2>

<p>这个参数接受<strong>虚拟架构</strong>作为参数，通常来说这个参数与最终编译出来的 PTX 代码无关，它只是作为编译 CUDA 代码时候的预处理参数。</p>

<p>在 CUDA 编程中提供了宏 <code class="language-plaintext highlighter-rouge">__CUDA_ARCH__</code> 可以通过这个宏来控制编译的内容，当编译参数为 <code class="language-plaintext highlighter-rouge">-arch=compute_35</code> 时，<code class="language-plaintext highlighter-rouge">__CUDA__ARCH__</code> 的值就是 350。</p>

<h2 id="gpu-code-code">–gpu-code(-code)</h2>

<p>这个参数指定了 CUDA 代码实际要编译、优化的 PTX 代码对应的 Nvidia GPU。 其中虚拟架构代码 <code class="language-plaintext highlighter-rouge">compute_xx</code> 用来指定 PTX 代码版本，真实架构代码 <code class="language-plaintext highlighter-rouge">sm_xx</code> 用来指定机器代码。 如果程序在执行前无法找到设备 GPU 对应的二进制代码，那么就是使用 JIT 从 PTX 代码中编译出对应的机器代码。</p>

<p>同时使用 <code class="language-plaintext highlighter-rouge">-arch</code> 与 <code class="language-plaintext highlighter-rouge">-code</code> 参数时候，要确保使用的虚拟架构与真实架构兼容的。</p>

<p>当编译时只提供了 <code class="language-plaintext highlighter-rouge">-arch</code> 参数，这个时候其实是 <code class="language-plaintext highlighter-rouge">-arch</code> 与 <code class="language-plaintext highlighter-rouge">-code</code> 的简写，<code class="language-plaintext highlighter-rouge">-code</code> 的值默认等于前者。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 提供虚拟架构代码</span>
nvcc <span class="nt">-arch</span><span class="o">=</span>compute_61 
<span class="c"># 等价于</span>
nvcc <span class="nt">-arch</span><span class="o">=</span>compute_61 <span class="nt">-code</span><span class="o">=</span>compute_61

<span class="c"># 提供真实架构代码</span>
nvcc <span class="nt">-arch</span><span class="o">=</span>sm_61 
<span class="c"># 等价于</span>
nvcc <span class="nt">-arch</span><span class="o">=</span>compute_61 <span class="nt">-code</span><span class="o">=</span>sm_61,compute_61
</code></pre></div></div>

<h2 id="胖二进制fat-binaries">胖二进制(Fat Binaries)</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nvcc x.cu 
	<span class="nt">-gencode</span> <span class="nb">arch</span><span class="o">=</span>compute_50,code<span class="o">=</span>sm_50
	<span class="nt">-gencode</span> <span class="nb">arch</span><span class="o">=</span>compute_60,code<span class="o">=</span>sm_60
	<span class="nt">-gencode</span> <span class="nb">arch</span><span class="o">=</span>compute_79,code<span class="o">=</span><span class="se">\'</span>compute_70,sm_70<span class="se">\'</span>
			
</code></pre></div></div>

<p>在编译的时候可以同时制定多套参数，编译出来的代码就可以支持多种不同架构的 GPU 设备，在具体执行的时候，驱动会选择当前真实架构对应的机器代码，如果找不到，那么就使用兼容的 PTX 代码 JIT 编译出对应的机器代码，这会导致在第一次执行时候速度会比较慢。</p>

<p>这种将同一份代码编译出多个不同架构代码的方式就叫”fat binaries”， 它带来的好处是让代码一次编译就能支持在多种设备上运行；它的缺点是，随着指定的架构版本越来越多，编译速度也越来越慢，编译出来的代码体积也越大。</p>]]></content><author><name></name></author><category term="matchinelearning" /><category term="deeplearning" /><category term="softwareenginer" /><category term="CUDA" /><summary type="html"><![CDATA[1 编译流程 随着 Nvidia 不断更新 GPU 硬件设计架构，每一代架构更迭都会引入新的功能，在同一代架构中不同的 GPU 型号在硬件配置上与性能上也会有一些细小的差异。 Nvidia 提供了一套代号来标识 GPU 的真实架构，它的格式是 sm_xy，x 代表 GPU 架构世代的编号，y代表 GPU 在这个架构世代中的版本号。为了方便对比 GPU 能力，如果 x1y1 &lt;= x2y2 那么sm_x1y1中所有非 ISA 相关的功能都包含在 sm_x2y2 中了。 然而这并不能保证新的 GPU 架构就能兼容老的 GPU 架构的二进制代码，比如在 Fermi 架构上编译的代码就无法在Kepler GPU 上运行，因为它们的指令集与指令编码都是不一样的。只用在相同的架构下才能保持二进制兼容。为了解决这个问题，CUDA 代码采用了两阶段编译过程。 第一个阶段 nvcc 编译器将 CUDA 代码编译成 PTX 代码，这是一种类似汇编的代码。它基于虚拟架构进行编译，虚拟架构是根据 GPU 能力、功能来定义的。 第二个阶段 nvcc 编译器是包含在 GPU 驱动中，编译器可以预先或者在运行的时候根据真实架构将 PTX 代码编译成实际的二进制代码。 第一个阶段的虚拟架构要兼容第二个阶段的真实架构，虚拟架构的版本越低就越能兼容更多的真实架构，当然CUDA 代码支持的功能也就越少。 对于在 CPU 上运行的 host code 与 GPU 上运行的 device code，编译器会分开进行编译。 nvcc 会将 device code (kernel 函数) 编译成 PTX code 或者二进制格式 (cubin object) 。 nvcc 会修改 host code 中调用 kernel 的部分，修改为 PTX code 或者 cubin object 中实际的代码。 架构代号列表 虚拟架构代号 真实架构代号 CUDA支持版本 支持架构 支持硬件 compute_50 sm_50 CUDA 6~11 Maxwell Tesla/Quadro M series compute_52 sm_52 CUDA 6~11 Maxwell GTX-980, GTX Titan X compute_53 sm_53 CUDA 6~11 Maxwell Tegra TX1, Jetson Nano compute_60 sm_60 CUDA 8 Pascal Tesla P100 compute_61 sm_61 CUDA 8 Pascal GTX 1080, GTX1070 compute_62 sm_62 CUDA 8 Pascal Jetson TX2 compute_70 sm_70 CUDA 9 Volta Tesla V100 compute_72 sm_72 CUDA 9 Volta Jetson AGX Xavier compute_75 sm_75 CUDA 10 Turing RTX 2080, RTX 2070 Tesla T4 compute_80 sm_80 CUDA 11.1 Ampere A100 compute_86 sm_86 CUDA 11.1 Ampere RTX 3090 compute_87 sm_87 CUDA 11.1 Ampere Jetson AGX Orin compute_89 sm_89 CUDA 11.8 Lovelace RTX 4090 compute_90 sm_90 CUDA 12 Hopper H100 H200 compute_95 sm_95 CUDA 12 Blackwell B100 2 PTX 上一节提到的 PTX (Parallel Thread Execution) 是 Nvidia 为 CUDA 设计的一种低级虚拟机和指令架构，它是CUDA 代码的中间表示形式，有以下特征： 由虚拟指令集定义：用一套虚拟的并行指令集，用于表示 CUDA 设备功能。 目标独立：采用抽象的寄存器和线程模型，不依赖于具体的 GPU 架构，可以针对不同的 GPU 生成优化机器代码。 可移植： PTX 代码可以在不同的 CUDA 运行环境和 GPU设备上执行。 JIT 编译： PTX 代码在执行前，有 GPU 驱动编译生成针对特定 GPU 的机器代码。 可读性好：PTX 代码结构类似汇编，以文本形式保存，便于阅读和调试。 虚拟寻址：提供了统一的虚拟寄存器和寻址空间 3 JIT 编译 PTX 代码在目标机器上执行前，会由 GPU 驱动将 PTX 代码优化、编译为机器代码。PTX 代码的编译结果会被缓存下来，以免重复编译。但是如果更新了 GPU 驱动，那么 PTX 代码会重新编译。 在不同操作系统下 JIT 缓存目录 操作系统 缓存目录 Linux ~/.nv/ComputeCache Windows %APPDATA\%NVIDIA\ComputeCache MacOS $HOME/Library/Application Support/NVIDIA/ComputeCache 与 JIT 相关的环境变量配置 环境变量 默认值 说明 CUDA_CACHE_DISABLE 0 是否禁用 JIT cache，1 代表禁用 0 代表不禁用 CUDA_CACHE_MAXSIZE 256MB cache 的尺寸，最大值 4GB， 在 334 版本驱动前，默认值是 32MB CUDA_CACHE_PATH 略 设置 cache 目录 CUDA_FORECE_PTX_JIT 0 设置为 1 时，强制忽略预编译好的机器代码，使用 JIT 从 PTX 代码中编译出机器代码 4 编译参数 arch &amp; code nvcc 编译器在编译 CDUA 代码的时候提供了 -gencode 参数，这个参数接收 arch=compute_xx 与 code=sm_xx 作为参数。也可以单独使用 -arch 和 -code 来指定。 nvcc x.cu -gencode arch=compute_50,code=sm_50 –gpu-architecture(-arch) 这个参数接受虚拟架构作为参数，通常来说这个参数与最终编译出来的 PTX 代码无关，它只是作为编译 CUDA 代码时候的预处理参数。 在 CUDA 编程中提供了宏 __CUDA_ARCH__ 可以通过这个宏来控制编译的内容，当编译参数为 -arch=compute_35 时，__CUDA__ARCH__ 的值就是 350。 –gpu-code(-code) 这个参数指定了 CUDA 代码实际要编译、优化的 PTX 代码对应的 Nvidia GPU。 其中虚拟架构代码 compute_xx 用来指定 PTX 代码版本，真实架构代码 sm_xx 用来指定机器代码。 如果程序在执行前无法找到设备 GPU 对应的二进制代码，那么就是使用 JIT 从 PTX 代码中编译出对应的机器代码。 同时使用 -arch 与 -code 参数时候，要确保使用的虚拟架构与真实架构兼容的。 当编译时只提供了 -arch 参数，这个时候其实是 -arch 与 -code 的简写，-code 的值默认等于前者。 # 提供虚拟架构代码 nvcc -arch=compute_61 # 等价于 nvcc -arch=compute_61 -code=compute_61 # 提供真实架构代码 nvcc -arch=sm_61 # 等价于 nvcc -arch=compute_61 -code=sm_61,compute_61 胖二进制(Fat Binaries) nvcc x.cu -gencode arch=compute_50,code=sm_50 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_79,code=\'compute_70,sm_70\' 在编译的时候可以同时制定多套参数，编译出来的代码就可以支持多种不同架构的 GPU 设备，在具体执行的时候，驱动会选择当前真实架构对应的机器代码，如果找不到，那么就使用兼容的 PTX 代码 JIT 编译出对应的机器代码，这会导致在第一次执行时候速度会比较慢。 这种将同一份代码编译出多个不同架构代码的方式就叫”fat binaries”， 它带来的好处是让代码一次编译就能支持在多种设备上运行；它的缺点是，随着指定的架构版本越来越多，编译速度也越来越慢，编译出来的代码体积也越大。]]></summary></entry><entry><title type="html">机器学习项目基础设施</title><link href="http://localhost:4000/matchinelearning/deeplearning/softwareenginer/2021/06/14/machine-learning-infrastructures.html" rel="alternate" type="text/html" title="机器学习项目基础设施" /><published>2021-06-14T00:00:00+08:00</published><updated>2021-06-14T00:00:00+08:00</updated><id>http://localhost:4000/matchinelearning/deeplearning/softwareenginer/2021/06/14/machine-learning-infrastructures</id><content type="html" xml:base="http://localhost:4000/matchinelearning/deeplearning/softwareenginer/2021/06/14/machine-learning-infrastructures.html"><![CDATA[<h1 id="机器学习项目基础设施">机器学习项目基础设施</h1>

<p>机器学习过程可以大体上分为三个部分数据管理、模型训练与生产部署。</p>

<p><img src="/assets/ml_infrastructure.png" alt="ml_infrastructure" /></p>

<p><em>图片来自课程 <a href="[Lecture 6: Infrastructure &amp; Tooling - Full Stack Deep Learning](https://fullstackdeeplearning.com/spring2021/lecture-6/)">Full Stack Deep Learning</a></em></p>

<h2 id="数据管理">数据管理</h2>

<h3 id="数据源sources">数据源(sources)</h3>

<p>数据源负责数据的存储与数据格式，常用的存储方式包括本地的文件系统、服务器上的对象存储。常用的数据格式有HDF5、Parquet 等。</p>

<h3 id="数据湖数据仓库">数据湖/数据仓库</h3>

<p>负责管理记录数据集，常见的数据湖软件/服务包括有：snowflake、databricks</p>

<h3 id="数据处理">数据处理</h3>

<p>数据处理有很多并行计算的框架</p>

<ul>
  <li>apache airflow：由 Airbnb 开源的计算框架，可以用来构建 DAG 计算图，实现数据的细粒度并行处理。</li>
  <li>spark：老牌数据流处理框架，支持 Java、Python 在内的多种语言。</li>
  <li>Dagster：和 airflow 一样也是一个数据计算的编排框架</li>
</ul>

<h3 id="数据分析">数据分析</h3>

<ul>
  <li>pandas：最常用的数据处理框架</li>
  <li>rapis: 基本上就是支持 GPU 计算的pandas</li>
</ul>

<h3 id="版本控制">版本控制</h3>

<ul>
  <li>DVC：全名叫 Data version control，专门负责数据版本控制还有模型版本控制的工具，它的操作基于git，通过对大文件的管理来实现版本控制。</li>
  <li>Pachyderm:  Pachyderm 不只是单纯的数据版本控制，还提供了数据生成pipeline的管理。</li>
</ul>

<h2 id="模型训练">模型训练</h2>

<h3 id="计算设备服务">计算设备&amp;服务</h3>

<p>本地的计算设备、各种云计算服务</p>

<h3 id="资源管理">资源管理</h3>

<p>Docke、sdetermined AI 等</p>

<h3 id="计算框架分布式训练框架">计算框架&amp;分布式训练框架</h3>

<p>深度学习框架：Pytorch、 tensorflow</p>

<p>深度学习库：<a href="http://fast.ai">fast.ai</a>、keras</p>

<p>分布式计算框架：RAY 等</p>

<h3 id="实验管理">实验管理</h3>

<ul>
  <li>TensorBoard：tensorflow 的可视化实验管理模块，现在独立出来，甚至 pytorch 都对他进行了支持。但是它没有对多个实验的管理能力。</li>
  <li>mlflow：是一款开源的试验管理工具，最大的特点是提供本地的实验管理功能，没有各种收费的云服务版本。</li>
  <li>weights &amp; biases: 是一款综合的实验管理工具，它除了提供实验追踪，还提供了数据可视化、模型调优等功能。但是 W&amp;B 是一款基于网络服务的实验管理工具。</li>
  <li><a href="http://Neptune.ai">Neptune.ai</a> <a href="http://comet.ml">comet.ml</a>:  也是基于网络服务的实验管理工具。</li>
</ul>

<h3 id="超参调试">超参调试</h3>

<ul>
  <li>SIGOPT</li>
  <li>Determined AI</li>
  <li>Weight &amp; Biases</li>
  <li>Tune</li>
</ul>

<h2 id="模型部署">模型部署</h2>

<h3 id="ci测试">CI&amp;测试</h3>

<ul>
  <li>Jenkins</li>
  <li>Gitlab CI</li>
  <li>Circle CI</li>
</ul>

<h3 id="边缘设备部署">边缘设备部署</h3>

<ul>
  <li>Nvidia TensorRT</li>
  <li>TensorFlow Lite</li>
</ul>]]></content><author><name></name></author><category term="matchinelearning" /><category term="deeplearning" /><category term="softwareenginer" /><summary type="html"><![CDATA[机器学习项目基础设施 机器学习过程可以大体上分为三个部分数据管理、模型训练与生产部署。 图片来自课程 Full Stack Deep Learning 数据管理 数据源(sources) 数据源负责数据的存储与数据格式，常用的存储方式包括本地的文件系统、服务器上的对象存储。常用的数据格式有HDF5、Parquet 等。 数据湖/数据仓库 负责管理记录数据集，常见的数据湖软件/服务包括有：snowflake、databricks 数据处理 数据处理有很多并行计算的框架 apache airflow：由 Airbnb 开源的计算框架，可以用来构建 DAG 计算图，实现数据的细粒度并行处理。 spark：老牌数据流处理框架，支持 Java、Python 在内的多种语言。 Dagster：和 airflow 一样也是一个数据计算的编排框架 数据分析 pandas：最常用的数据处理框架 rapis: 基本上就是支持 GPU 计算的pandas 版本控制 DVC：全名叫 Data version control，专门负责数据版本控制还有模型版本控制的工具，它的操作基于git，通过对大文件的管理来实现版本控制。 Pachyderm: Pachyderm 不只是单纯的数据版本控制，还提供了数据生成pipeline的管理。 模型训练 计算设备&amp;服务 本地的计算设备、各种云计算服务 资源管理 Docke、sdetermined AI 等 计算框架&amp;分布式训练框架 深度学习框架：Pytorch、 tensorflow 深度学习库：fast.ai、keras 分布式计算框架：RAY 等 实验管理 TensorBoard：tensorflow 的可视化实验管理模块，现在独立出来，甚至 pytorch 都对他进行了支持。但是它没有对多个实验的管理能力。 mlflow：是一款开源的试验管理工具，最大的特点是提供本地的实验管理功能，没有各种收费的云服务版本。 weights &amp; biases: 是一款综合的实验管理工具，它除了提供实验追踪，还提供了数据可视化、模型调优等功能。但是 W&amp;B 是一款基于网络服务的实验管理工具。 Neptune.ai comet.ml: 也是基于网络服务的实验管理工具。 超参调试 SIGOPT Determined AI Weight &amp; Biases Tune 模型部署 CI&amp;测试 Jenkins Gitlab CI Circle CI 边缘设备部署 Nvidia TensorRT TensorFlow Lite]]></summary></entry><entry><title type="html">机器学习中的交叉熵</title><link href="http://localhost:4000/machinelearning/math/2020/09/27/cross-entropy.html" rel="alternate" type="text/html" title="机器学习中的交叉熵" /><published>2020-09-27T14:11:00+08:00</published><updated>2020-09-27T14:11:00+08:00</updated><id>http://localhost:4000/machinelearning/math/2020/09/27/cross-entropy</id><content type="html" xml:base="http://localhost:4000/machinelearning/math/2020/09/27/cross-entropy.html"><![CDATA[<h1 id="机器学习中的交叉熵">机器学习中的交叉熵</h1>

<p>交叉熵损失函数是机器学习分类问题中最常用的一个损失函数。但是很多人对于“交叉熵”的概念缺乏理解。本文的目的是希望能够通俗易懂的解释清楚 “熵”， “交叉熵” 和 “KL-散度” 这三个相关的概念。</p>

<h2 id="信息论中的熵">信息论中的“熵”</h2>

<p>“熵” (entropy) 这个概念在热力学中表示一个系统的无序程度，熵越大系统就越混乱。1948年香农在其发表的《通信的数学理论》论文中给出了”信息熵“的定义：信息熵是随机事件不确定性的度量。信息熵与热力学熵有着紧密的内在联系，不过在本文中所讨论的熵都是指信息熵。</p>

<h3 id="有效信息长度">有效信息长度</h3>

<p>为了能更好的解释信息熵，我们先来看一个例子。有一个气象监测站，通过检测某地的气象数据，能给出第二天的天气预测。气象站需要将预测结果网络发送给气象中心。如果当地只有两种天气一种是晴天，一种是雨天，那么气象站如何能够高效的发送预测结果呢？最简单的情况下，气象站可以将预测结果以汉字的形式发送出去。如果预测是晴天就发送”晴天“，如果是雨天就发送”雨天“。我们知道一个汉字在计算机中通常的编码长度是 2 byte，也就是 8 bit，那么这两个汉字就是 16 bit。为了能更高效的发送信息，我们可以对信息进行编码，用 0 来表示晴天，1 来表示雨天。那么我们需要发送的信息长度就只有 1 bit 了。对于原来长度为 16 bit 的信息来说，它<strong>真正有效的信息长度</strong>其实只有 1 bit。</p>

<p><img src="/assets/entropy1.png" alt="weather_2" /></p>

<p>那如果当地天气有8种情况，我们需要多少长度的消息才能发送预测结果呢？答案很简单：\(2^3=8\) ，我们只需要3个 bit 就能发送8种天气。在计算机中对于任意n种分类情况，我们只需要 \(log_2 (n)\) 长度的编码信息就可以把所有的情况进行编码。</p>

<p><img src="/assets/entropy2.png" alt="c" /></p>

<h3 id="信息熵">信息熵</h3>

<p>我们知道在现实中，第二天出现什么天气的概率不是均等的，在夏天出现晴天和雨天的概率比较大，而出现雪天的概率很小；而在冬天出现雨天的概率较小，出现雪天的概率较大。在第一个例子中如果晴天的概率是 75%， 雨天的概率是 25%，那么消息的长度应该是多少呢？在计算消息长度之前，我们需要先介绍“熵减因子”(reduction factor)的概念。按照香农在论文中提出：</p>

<blockquote>
  <p>每发送1个bit的有效信息，能减少了接收者2个因子的不确定性。</p>
</blockquote>

<p><strong>熵减因子</strong> m 与有<strong>效消息长度</strong> u 之间的关系是： \(2^u=m\)</p>

<p>在已知事件概率的情况下，熵减因子 m 与概率 p 的关系是： \(\frac{1}{p}=m\)</p>

<p>基于熵减因子与概率的关系，我们可以根据概率 p 推断出有效信息的长度 u 的关系:  \(-log_2{p} = u\)</p>

<p><img src="/assets/entropy4.png" alt="wheather_4" /></p>

<p>现在我们可以回答之前提出的问题了。</p>

<p><strong>晴天的有效信息长度</strong>  \(m_s = -log_2{p_s} = -log_2{0.75} = 0.41\)</p>

<p><strong>雨天的有效信息长度</strong> \(m_r = -log_2{p_r} = -log_2{0.25} = 2\)</p>

<p><strong>平均有效信息长度</strong> \(m_{avg} = p_s * (-log_2{p_s}) + p_r * (-log_2{p_r}) = 0.75 * 0.41 + 0.25 * 2 = 0.81\)</p>

<p>平均有效信息长度又被称为<strong>信息熵</strong> , 数学定义为：</p>

\[\text{Entropy},H(p) = - \sum{p(i)*log(p(i))}\]

<p>我们按照现实情况，分别给第二个例子中8种天气加一个概率。</p>

<p><img src="/assets/entropy3.png" alt="weather_8_prob" /></p>

<p>按照信息熵的定义，我们可以计算出此时的信息熵：</p>

\[\begin{aligned} 
\text{Entropy} &amp; = -0.35 * log_2{0.35} -0.35 * log_2{0.35} \\
 &amp; -0.10 * log_2{0.10} -0.10 * log_2{0.10} \\
 &amp; -0.04 * log_2{0.04} -0.04 * log_2{0.04} \\
 &amp; -0.01 * log_2{0.01} -0.01 * log_2{0.01} \\
 &amp; = 2.23
\end{aligned}\]

<p><strong>信息熵是理论上最小的平均消息长度</strong>。</p>

<h3 id="交叉熵">交叉熵</h3>

<p>通过信息熵公式我们可以计算出，理论上发送信息的最小平均长度是 2.23，上图因为多所有天气都按照3位进行编码，所以消息的平均长度是3。通过修改信息的编码方式，我们可以降低消息的平均长度。</p>

<p><img src="/assets/entropy5.png" alt="weather_9_prob" /></p>

<p>通过减小高概率天气的消息长度，增长低概率天气的消息长度，我们可以降低平均的消息长度。
\(0.35 * 2 + 0.35 * 2 + 0.1 * 3+ 0.1 * 3 + 0.04 * 4 + 0.04 * 4  + 0.01 * 4 + 0.01 * 5 = 2.42\)
<img src="/assets/entropy6.png" alt="weather_10_prob" /></p>

<p>如果我们反过来增长低概率天气的消息长度，减小大概率天气的长度，那么消息的平均长度增大。
\(0.01 * 2 + 0.01 * 2 + 0.04 * 3 + 0.04 * 3 + 0.1 * 4 + 0.1 * 4 + 0.35 * 5 + 0.35 * 5 = 4.58\)</p>

<p>上面两个例子中，我们计算信息平均长度时，是用真实的天气概率乘以我们<strong>给定的有效信息长度</strong>， 上面计算结果叫做<strong>交叉熵</strong>。</p>

<p>在已知各种情况天气的概率下，可以通过信息熵的公式计算出理论上最小的平均信息长度。但是在现实生活中，我们经常是不知道各种情况的实际概率分布的。在这种情况下，我们可以预先给出一个对于真实概率分布的一个估计（在上面的例子是预先给出一个信息长度）。
<img src="/assets/entropy7.png" alt="weather_11_prob" /></p>

<p>图中红色的概率代表天气的真实分布，而蓝色概率代表按照编码长度推算出来的对于天气概率的估计。真实的概率分布于估计概率分布之间的关系可以用<strong>交叉熵</strong>的形式表达出来。</p>

\[\text{CrossEntropy,}H(p,q) = - \sum{p(i)log(q(i))}\]

<p>通过前面的内容我们可以知道，只有<strong>估计概率越接近于真正的概率，交叉熵才会越小，当估计概率等于真实概率时，交叉熵等于信息熵。</strong></p>

<p>交叉熵公式于信息熵公式的不同之处在于，将 log 部分的概率分布替换成了<strong>预测概率分布</strong>。<strong>交叉熵大于信息熵的部分叫做Kullback-Leibler Divergence（KL散度）也叫相对熵（Relative Entropy）</strong>。</p>

\[\begin{aligned}
\text{KL-Divergence} &amp;= \text{Entropy} - \text{CrossEntropy}  \\
D_{KL}(p||q) &amp; = H(p,q) - H(p) \\
&amp; = -\sum_i{p_ilog(q_i)} - (-\sum_i{p_ilog(p_i)}) \\
&amp; = -\sum_i{p_ilog(q_i)} + \sum_i{p_ilog(p_i)} \\
&amp; = \sum_i{p_i log(\frac{p_i}{q_i})}
\end{aligned}\]

<h2 id="交叉熵在机器学习中的应用">交叉熵在机器学习中的应用</h2>

<p>由于交叉熵的性质，所以在机器学习中，交叉熵被广泛的作为<strong>分类损失函数</strong>。</p>

<p><img src="/assets/ce_loss.png" alt="ce_loss" /></p>

<p>在一个分类任务的训练过程中，我们已知目标的真实概率分布，分类器在每次的训练过程中会给出一个预测的概率分布。我们把<strong>交叉熵</strong>作为我们的目标函数，优化的方向是使得目标函数（交叉熵）最小，交叉熵只有在预测概率分布于真实概率分布一致的情况下最小，所以交叉熵非常适合作为分类任务的损失函数。</p>

<p>在信息论中<strong>信息熵</strong>，<strong>交叉熵</strong>公式中的 log 都是以 2 为底的对数，但是在机器学习中代码实现中，无论是用以10为底或者e为底都无所谓，因为对数都可以通过换底公式进行变换： \(log_e{n} = \frac{log_2{n}}{log_2{e}}\) ，因为分母始终是一个常数所以对于损失函数没有影响。</p>

<p>信息熵原本作为信息论的一个重要概念，没有想到在多年以后会在机器学习中继续大放异彩。希望通过本文的内容能理解<strong>交叉熵损失函数</strong>真正的意义。本文是根据文章 <a href="https://towardsdatascience.com/entropy-cross-entropy-and-kl-divergence-explained-b09cdae917a">Entropy, Cross-Entropy, and KL-Divergence Explained!</a> 进行的改写，读者可以阅读原文获得跟多关于交叉熵的认识。</p>]]></content><author><name></name></author><category term="machinelearning" /><category term="math" /><summary type="html"><![CDATA[机器学习中的交叉熵]]></summary></entry><entry><title type="html">pkg-config 入门</title><link href="http://localhost:4000/c++/linux/2020/07/26/pkg-config-introduction.html" rel="alternate" type="text/html" title="pkg-config 入门" /><published>2020-07-26T00:41:00+08:00</published><updated>2020-07-26T00:41:00+08:00</updated><id>http://localhost:4000/c++/linux/2020/07/26/pkg-config-introduction</id><content type="html" xml:base="http://localhost:4000/c++/linux/2020/07/26/pkg-config-introduction.html"><![CDATA[<h1 id="pkg-config-入门">pkg-config 入门</h1>

<p>pkg-config 是类 Unix 操作系统上的一个库查询工具。它通过 .pc 文件来查询当前系统上已安装类库的信息。</p>

<p>下面是 OpenCV4 的 pc 文件， 文件中包含了OpenCV 库的很多元数据(metadata)</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Package Information for pkg-config

prefix=/usr/local/opencv4
exec_prefix=${prefix}
libdir=${exec_prefix}/lib
includedir_old=${prefix}/include/opencv4/opencv
includedir_new=${prefix}/include/opencv4

Name: OpenCV
Description: Open Source Computer Vision Library
Version: 4.0.1
Libs: -L${exec_prefix}/lib -lopencv_gapi -lopencv_stitching -lopencv_aruco -lopencv_bgsegm -lopencv_bioinspired -lopencv_ccalib -lopencv_cvv -lopencv_dnn_objdetect -lopencv_dpm -lopencv_face -lopencv_freetype -lopencv_fuzzy -lopencv_hdf -lopencv_hfs -lopencv_img_hash -lopencv_line_descriptor -lopencv_reg -lopencv_rgbd -lopencv_saliency -lopencv_sfm -lopencv_stereo -lopencv_structured_light -lopencv_phase_unwrapping -lopencv_superres -lopencv_optflow -lopencv_surface_matching -lopencv_tracking -lopencv_datasets -lopencv_text -lopencv_dnn -lopencv_plot -lopencv_videostab -lopencv_video -lopencv_xfeatures2d -lopencv_shape -lopencv_ml -lopencv_ximgproc -lopencv_xobjdetect -lopencv_objdetect -lopencv_calib3d -lopencv_features2d -lopencv_highgui -lopencv_videoio -lopencv_imgcodecs -lopencv_flann -lopencv_xphoto -lopencv_photo -lopencv_imgproc -lopencv_core
Libs.private: -ldl -lm -lpthread -lrt
Cflags: -I${includedir_old} -I${includedir_new}
</code></pre></div></div>

<p>pc 文件中的元数据分为两种，一种是格式如 <code>prefix=**</code> 的变量，一种是格式如 <code>Name: OpenCV</code> 关键字，变量是在 pc 文件内部使用，用来帮助定义关键字；而关键字信息会导出到 pkg-config 中。</p>

<p>pkg-config 中定义了一下这些关键字</p>

<ul>
  <li>Name: 当前库的名字，它不需要全局唯一，通常它和 pc 文件的文件名保持一致。</li>
  <li>Description: 对于库的简短描述</li>
  <li>URL: 当前库的相关信息网络地址</li>
  <li>Version: 安装的版本号</li>
  <li>Requires: 列出当前库所需要的依赖，依赖库的版本信息可以使用 =, &gt;, &lt;, &lt;= 和 &gt;= 来指定。 eg. <code>Requires: OpenCV &gt;= 4.0.0</code></li>
  <li>Requires.private: 列出当前库所需要的依赖，但是这些依赖并不会暴露给应用，版本格式与 <code>Requires</code> 相同。</li>
  <li>Confilcts: 这是一个可选关键字，用来指明与当前库冲突的库</li>
  <li>Cflags: 编译当前库需要的 flags 参数。如果依赖的库不支持 pkg-config， 就可以通过此关键字来指定，如果支持 pkg-config，就应该在 <code>Requires</code> 和 <code>Requires.private</code> 中指定。</li>
  <li>Libs: 指定不支持 pkg-config 的链接依赖 flags 参数</li>
  <li>Libs.private: 同 <code>Requires.private</code> 一样，当前关键字的依赖不会暴露给应用</li>
</ul>

<p>pkg-config 默认会在 <code>/usr/lib/pkgconfig</code> 和 <code>/usr/share/pkgconfig</code> 中去加载 pc 文件，但是有些库的安装地址不在默认路径中，就需要将 pc 文件的路径添加到环境变量 <strong>PKG_CONFIG_PATH</strong> 中。</p>

<p>通过 pkg-config 可以查看安装库的版本</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pkg-config <span class="nt">--modversion</span> opencv4 <span class="c"># 如果 pc 文件名与 Name 关键字不一致，这里需要输入的是文件名</span>
4.0.1
</code></pre></div></div>

<p><code>--libs</code> 可以输出编译依赖当前库的 link flags， 但是不会输出 /usr/lib 下的依赖库。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pkg-config <span class="nt">--libs</span> opencv4
<span class="nt">-L</span>/usr/local/opencv4/lib <span class="nt">-lopencv_gapi</span> <span class="nt">-lopencv_stitching</span> <span class="nt">-lopencv_aruco</span> <span class="nt">-lopencv_bgsegm</span> <span class="nt">-lopencv_bioinspired</span> <span class="nt">-lopencv_ccalib</span> <span class="nt">-lopencv_cvv</span> <span class="nt">-lopencv_dnn_objdetect</span> <span class="nt">-lopencv_dpm</span> <span class="nt">-lopencv_face</span> <span class="nt">-lopencv_freetype</span> <span class="nt">-lopencv_fuzzy</span> <span class="nt">-lopencv_hdf</span> <span class="nt">-lopencv_hfs</span> <span class="nt">-lopencv_img_hash</span> <span class="nt">-lopencv_line_descriptor</span> <span class="nt">-lopencv_reg</span> <span class="nt">-lopencv_rgbd</span> <span class="nt">-lopencv_saliency</span> <span class="nt">-lopencv_sfm</span> <span class="nt">-lopencv_stereo</span> <span class="nt">-lopencv_structured_light</span> <span class="nt">-lopencv_phase_unwrapping</span> <span class="nt">-lopencv_superres</span> <span class="nt">-lopencv_optflow</span> <span class="nt">-lopencv_surface_matching</span> <span class="nt">-lopencv_tracking</span> <span class="nt">-lopencv_datasets</span> <span class="nt">-lopencv_text</span> <span class="nt">-lopencv_dnn</span> <span class="nt">-lopencv_plot</span> <span class="nt">-lopencv_videostab</span> <span class="nt">-lopencv_video</span> <span class="nt">-lopencv_xfeatures2d</span> <span class="nt">-lopencv_shape</span> <span class="nt">-lopencv_ml</span> <span class="nt">-lopencv_ximgproc</span> <span class="nt">-lopencv_xobjdetect</span> <span class="nt">-lopencv_objdetect</span> <span class="nt">-lopencv_calib3d</span> <span class="nt">-lopencv_features2d</span> <span class="nt">-lopencv_highgui</span> <span class="nt">-lopencv_videoio</span> <span class="nt">-lopencv_imgcodecs</span> <span class="nt">-lopencv_flann</span> <span class="nt">-lopencv_xphoto</span> <span class="nt">-lopencv_photo</span> <span class="nt">-lopencv_imgproc</span> <span class="nt">-lopencv_core</span>
</code></pre></div></div>

<p>同时 <code>--libs</code> 也不会输出 OpenCV 的依赖，因为依赖 OpenCV 的代码并不直接依赖与OpenCV 的依赖。为了静态链接，可以加上选项 <code>--static</code></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pkg-config <span class="nt">--libs</span> opencv4
<span class="nt">-L</span>/usr/local/opencv4/lib <span class="nt">-lopencv_gapi</span> <span class="nt">-lopencv_stitching</span> <span class="nt">-lopencv_aruco</span> <span class="nt">-lopencv_bgsegm</span> <span class="nt">-lopencv_bioinspired</span> <span class="nt">-lopencv_ccalib</span> <span class="nt">-lopencv_cvv</span> <span class="nt">-lopencv_dnn_objdetect</span> <span class="nt">-lopencv_dpm</span> <span class="nt">-lopencv_face</span> <span class="nt">-lopencv_freetype</span> <span class="nt">-lopencv_fuzzy</span> <span class="nt">-lopencv_hdf</span> <span class="nt">-lopencv_hfs</span> <span class="nt">-lopencv_img_hash</span> <span class="nt">-lopencv_line_descriptor</span> <span class="nt">-lopencv_reg</span> <span class="nt">-lopencv_rgbd</span> <span class="nt">-lopencv_saliency</span> <span class="nt">-lopencv_sfm</span> <span class="nt">-lopencv_stereo</span> <span class="nt">-lopencv_structured_light</span> <span class="nt">-lopencv_phase_unwrapping</span> <span class="nt">-lopencv_superres</span> <span class="nt">-lopencv_optflow</span> <span class="nt">-lopencv_surface_matching</span> <span class="nt">-lopencv_tracking</span> <span class="nt">-lopencv_datasets</span> <span class="nt">-lopencv_text</span> <span class="nt">-lopencv_dnn</span> <span class="nt">-lopencv_plot</span> <span class="nt">-lopencv_videostab</span> <span class="nt">-lopencv_video</span> <span class="nt">-lopencv_xfeatures2d</span> <span class="nt">-lopencv_shape</span> <span class="nt">-lopencv_ml</span> <span class="nt">-lopencv_ximgproc</span> <span class="nt">-lopencv_xobjdetect</span> <span class="nt">-lopencv_objdetect</span> <span class="nt">-lopencv_calib3d</span> <span class="nt">-lopencv_features2d</span> <span class="nt">-lopencv_highgui</span> <span class="nt">-lopencv_videoio</span> <span class="nt">-lopencv_imgcodecs</span> <span class="nt">-lopencv_flann</span> <span class="nt">-lopencv_xphoto</span> <span class="nt">-lopencv_photo</span> <span class="nt">-lopencv_imgproc</span> <span class="nt">-lopencv_core</span> <span class="nt">-ldl</span> <span class="nt">-lm</span> <span class="nt">-lpthread</span> <span class="nt">-lrt</span>
</code></pre></div></div>

<p>使用 <code>--cflags</code> pkg-config 会输出所有的编译flag， 加不加 <code>--static</code> 都一样。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pkg-config <span class="nt">--cflags</span> opencv4
<span class="nt">-I</span>/usr/local/opencv4/include/opencv4/opencv <span class="nt">-I</span>/usr/local/opencv4/include/opencv4

pkg-config <span class="nt">--cflags</span> <span class="nt">--static</span> opencv4
<span class="nt">-I</span>/usr/local/opencv4/include/opencv4/opencv <span class="nt">-I</span>/usr/local/opencv4/include/opencv4
</code></pre></div></div>

<p>使用 pkg-config 可以更加方便的编译C++代码，比如代码 <code>myapp.cpp</code> 依赖 OpenCV，那么可以使用下面方式来指定编译的flags</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>g++ <span class="sb">`</span>pkg-config <span class="nt">--cflags</span> <span class="nt">--libs</span> opencv4<span class="sb">`</span> <span class="nt">-o</span> myapp myapp.cpp
</code></pre></div></div>]]></content><author><name></name></author><category term="c++" /><category term="linux" /><summary type="html"><![CDATA[pkg-config 入门 pkg-config 是类 Unix 操作系统上的一个库查询工具。它通过 .pc 文件来查询当前系统上已安装类库的信息。 下面是 OpenCV4 的 pc 文件， 文件中包含了OpenCV 库的很多元数据(metadata) # Package Information for pkg-config prefix=/usr/local/opencv4 exec_prefix=${prefix} libdir=${exec_prefix}/lib includedir_old=${prefix}/include/opencv4/opencv includedir_new=${prefix}/include/opencv4 Name: OpenCV Description: Open Source Computer Vision Library Version: 4.0.1 Libs: -L${exec_prefix}/lib -lopencv_gapi -lopencv_stitching -lopencv_aruco -lopencv_bgsegm -lopencv_bioinspired -lopencv_ccalib -lopencv_cvv -lopencv_dnn_objdetect -lopencv_dpm -lopencv_face -lopencv_freetype -lopencv_fuzzy -lopencv_hdf -lopencv_hfs -lopencv_img_hash -lopencv_line_descriptor -lopencv_reg -lopencv_rgbd -lopencv_saliency -lopencv_sfm -lopencv_stereo -lopencv_structured_light -lopencv_phase_unwrapping -lopencv_superres -lopencv_optflow -lopencv_surface_matching -lopencv_tracking -lopencv_datasets -lopencv_text -lopencv_dnn -lopencv_plot -lopencv_videostab -lopencv_video -lopencv_xfeatures2d -lopencv_shape -lopencv_ml -lopencv_ximgproc -lopencv_xobjdetect -lopencv_objdetect -lopencv_calib3d -lopencv_features2d -lopencv_highgui -lopencv_videoio -lopencv_imgcodecs -lopencv_flann -lopencv_xphoto -lopencv_photo -lopencv_imgproc -lopencv_core Libs.private: -ldl -lm -lpthread -lrt Cflags: -I${includedir_old} -I${includedir_new} pc 文件中的元数据分为两种，一种是格式如 prefix=** 的变量，一种是格式如 Name: OpenCV 关键字，变量是在 pc 文件内部使用，用来帮助定义关键字；而关键字信息会导出到 pkg-config 中。 pkg-config 中定义了一下这些关键字 Name: 当前库的名字，它不需要全局唯一，通常它和 pc 文件的文件名保持一致。 Description: 对于库的简短描述 URL: 当前库的相关信息网络地址 Version: 安装的版本号 Requires: 列出当前库所需要的依赖，依赖库的版本信息可以使用 =, &gt;, &lt;, &lt;= 和 &gt;= 来指定。 eg. Requires: OpenCV &gt;= 4.0.0 Requires.private: 列出当前库所需要的依赖，但是这些依赖并不会暴露给应用，版本格式与 Requires 相同。 Confilcts: 这是一个可选关键字，用来指明与当前库冲突的库 Cflags: 编译当前库需要的 flags 参数。如果依赖的库不支持 pkg-config， 就可以通过此关键字来指定，如果支持 pkg-config，就应该在 Requires 和 Requires.private 中指定。 Libs: 指定不支持 pkg-config 的链接依赖 flags 参数 Libs.private: 同 Requires.private 一样，当前关键字的依赖不会暴露给应用 pkg-config 默认会在 /usr/lib/pkgconfig 和 /usr/share/pkgconfig 中去加载 pc 文件，但是有些库的安装地址不在默认路径中，就需要将 pc 文件的路径添加到环境变量 PKG_CONFIG_PATH 中。 通过 pkg-config 可以查看安装库的版本 pkg-config --modversion opencv4 # 如果 pc 文件名与 Name 关键字不一致，这里需要输入的是文件名 4.0.1 --libs 可以输出编译依赖当前库的 link flags， 但是不会输出 /usr/lib 下的依赖库。 pkg-config --libs opencv4 -L/usr/local/opencv4/lib -lopencv_gapi -lopencv_stitching -lopencv_aruco -lopencv_bgsegm -lopencv_bioinspired -lopencv_ccalib -lopencv_cvv -lopencv_dnn_objdetect -lopencv_dpm -lopencv_face -lopencv_freetype -lopencv_fuzzy -lopencv_hdf -lopencv_hfs -lopencv_img_hash -lopencv_line_descriptor -lopencv_reg -lopencv_rgbd -lopencv_saliency -lopencv_sfm -lopencv_stereo -lopencv_structured_light -lopencv_phase_unwrapping -lopencv_superres -lopencv_optflow -lopencv_surface_matching -lopencv_tracking -lopencv_datasets -lopencv_text -lopencv_dnn -lopencv_plot -lopencv_videostab -lopencv_video -lopencv_xfeatures2d -lopencv_shape -lopencv_ml -lopencv_ximgproc -lopencv_xobjdetect -lopencv_objdetect -lopencv_calib3d -lopencv_features2d -lopencv_highgui -lopencv_videoio -lopencv_imgcodecs -lopencv_flann -lopencv_xphoto -lopencv_photo -lopencv_imgproc -lopencv_core 同时 --libs 也不会输出 OpenCV 的依赖，因为依赖 OpenCV 的代码并不直接依赖与OpenCV 的依赖。为了静态链接，可以加上选项 --static pkg-config --libs opencv4 -L/usr/local/opencv4/lib -lopencv_gapi -lopencv_stitching -lopencv_aruco -lopencv_bgsegm -lopencv_bioinspired -lopencv_ccalib -lopencv_cvv -lopencv_dnn_objdetect -lopencv_dpm -lopencv_face -lopencv_freetype -lopencv_fuzzy -lopencv_hdf -lopencv_hfs -lopencv_img_hash -lopencv_line_descriptor -lopencv_reg -lopencv_rgbd -lopencv_saliency -lopencv_sfm -lopencv_stereo -lopencv_structured_light -lopencv_phase_unwrapping -lopencv_superres -lopencv_optflow -lopencv_surface_matching -lopencv_tracking -lopencv_datasets -lopencv_text -lopencv_dnn -lopencv_plot -lopencv_videostab -lopencv_video -lopencv_xfeatures2d -lopencv_shape -lopencv_ml -lopencv_ximgproc -lopencv_xobjdetect -lopencv_objdetect -lopencv_calib3d -lopencv_features2d -lopencv_highgui -lopencv_videoio -lopencv_imgcodecs -lopencv_flann -lopencv_xphoto -lopencv_photo -lopencv_imgproc -lopencv_core -ldl -lm -lpthread -lrt 使用 --cflags pkg-config 会输出所有的编译flag， 加不加 --static 都一样。 pkg-config --cflags opencv4 -I/usr/local/opencv4/include/opencv4/opencv -I/usr/local/opencv4/include/opencv4 pkg-config --cflags --static opencv4 -I/usr/local/opencv4/include/opencv4/opencv -I/usr/local/opencv4/include/opencv4 使用 pkg-config 可以更加方便的编译C++代码，比如代码 myapp.cpp 依赖 OpenCV，那么可以使用下面方式来指定编译的flags g++ `pkg-config --cflags --libs opencv4` -o myapp myapp.cpp]]></summary></entry><entry><title type="html">机器学习基石 第二讲</title><link href="http://localhost:4000/machinelearning/deeplearning/math/2020/07/12/machine-learning-foundations-lession-2.html" rel="alternate" type="text/html" title="机器学习基石 第二讲" /><published>2020-07-12T01:26:21+08:00</published><updated>2020-07-12T01:26:21+08:00</updated><id>http://localhost:4000/machinelearning/deeplearning/math/2020/07/12/machine-learning-foundations-lession-2</id><content type="html" xml:base="http://localhost:4000/machinelearning/deeplearning/math/2020/07/12/machine-learning-foundations-lession-2.html"><![CDATA[<h1 id="感知机">感知机</h1>

<h2 id="感知器假设集perceptron-hypothesis-set">感知器假设集（Perceptron Hypothesis Set）</h2>
<p>感知器算法:  \(h(x)=sign((\sum_{i=1}^dw_ix_i)-threshold)\)</p>

<p>对上面的公示进行变形，将<strong>threshold</strong>作为偏置，纳入 x 中，\(x_0=+1\) ;</p>

\[h(x)=sign(W^TX)\]

<p>每一个不同的W代表了算法中的一个hypothesis.</p>

<h2 id="pla-感知器学习算法">PLA 感知器学习算法</h2>

<p>要从 hypothesis set 中找到一个合适的 hypothesis g, 让 g 与目标函数 f 尽可能的相近。</p>

<p>PLA算法通过试错的方法实现模型的训练：</p>

<p>总共进行t轮的训练， t=0, 1, …</p>

<ol>
  <li>
    <p>随机初始化 \(w_0\);</p>
  </li>
  <li>
    <p>将样本 \((x_{n(t)},y_{n(t)})\) 带入PLA学习机， 如果：</p>
  </li>
</ol>

\[sign(w^T_tx_{n(t)})\neq y_{n(t)}\]

<p>那么，表示发生错误，需要对错误进行纠正。</p>

<ol>
  <li>
    <p>修正错误：</p>

\[w_{t+1} \leftarrow w_t + y_{n(t)}x_{n(t)}\]

    <p>\(w\): 代表分类线的法向量
\(x_n\): 是原点到 \(x_n\) 的向量</p>

    <p><img src="/assets/ml_base_2_1.png" alt="ml_base_2_1" /></p>
  </li>
</ol>

<ul>
  <li>当 \(y_n = +1\), 将 \(w\) 的方向向样本 \((x_n, y_n)\) 的方向转动。</li>
  <li>当 \(y_n = -1\), 将\(w\)的方向向样本 \((x_n, y_n)\) 的反方向转动。</li>
  <li>当不再出现错误的时候，训练结束。</li>
</ul>

<p><strong>PLA算法要能终止，要求训练数据集必须是线性可分的</strong></p>

<p><strong>\(w_t\) 越来越接近 \(w_f\)</strong></p>

<ul>
  <li>
    <p>\(w_f\): 目标函数 f 对应的参数，因此对于任意一个样本，它都能正确的分类：</p>

\[y_{n(t)}w^T_fx_{n(t)} \ge \min_ny_nw^T_fx_n \gt 0\]
  </li>
  <li>
    <p>衡量两个向量是否接近，可以用它们的内积，如果内积越小代表它们越不接近，相互垂直时为 0</p>

\[\begin{align}
\begin{split}
w_f^Tw_{t+1} &amp;= w_f^T(w_t+y_{n(t)}x_{n(t)}) \\
&amp;\ge w_f^Tw_t + \min_ny_nw_f^Tx_n \\
&amp;\gt w_f^Tw_t + 0
\end{split}
\end{align}\]
  </li>
</ul>

<p><strong>\(w_t\) 的增长速率不快</strong></p>

<p>\(w_t\)每次的更新不超过离分割线最远的样本的距离</p>

<ul>
  <li>\(w_t\) 的每次更新发生在有错误的时候：</li>
</ul>

\[sign(w_t^fx_{n(t)}) \neq y_{n(t)} \Leftrightarrow y_{n(t)}w_t^Tx_{n(t)} \leq 0\]

<ul>
  <li>对于每一次更新后的结果：</li>
</ul>

\[\begin{equation}\begin{split} ||w_{t+1}||^2 &amp;= ||w_t + y_{n(t)}x_{n(t)}||^2\\\\
   &amp;= ||w_t||^2 + 2y_{n(t)}w_t^Tx_{n(t)} + ||y_{n(t)}x_{n(t)}||^2\\\\
   &amp;\le ||w_t||^2 + 0 + ||y_{n(t)x_{n(t)}}||^2\\\\
   &amp;\le ||w_t||^2 + \max_n||y_{n(t)}x_{n(t)}||^2\end{split}\end{equation}\]

<p>其中  \(\max_n \Vert y_{n(t)}x_{n(t)} \Vert ^2\)  就代表了距离到分隔线最远的点的距离。</p>

\[\begin{equation}\begin{split}
   \text{start from w_0 = 0, after T mistake corrections,} \\
   
   \frac{w_f^T}{\Vert w_f \Vert} \frac{w_T}{\Vert w_T \Vert} \ge \sqrt T * \text{constant}
   
   \end{split}\end{equation}\]

<p>\(w_f^Tw_{t+1}\) 的内积是小于等于1的，再根据上面的式子，知道T不可能为无穷大，所以运算会终止。</p>

<h2 id="pocket-算法">Pocket 算法</h2>
<p><strong>算法步骤</strong></p>

<ol>
  <li>随机初始化 w</li>
  <li>进行 t 轮的学习， t = 0, 1, …</li>
  <li>如果发生错误，按照 PLA 算法对 w进行纠正：\(w_{t+1} \leftarrow w_t + y_{n(t)}x_{n(t)}\)</li>
  <li>判断对比纠正后的算法与之前算法的错误率，如果更好，者保留新的w<sub>t+1</sub>, 否者保留之前的w。</li>
  <li>运算足够多次之后停止运算。</li>
</ol>

<p>Pocket算法是PLA的改进算法，用于解决<strong>线性不可分</strong>的数据集。
Pocket算法的运算量大：对于比PLA，在得到新的w<sub>t+1</sub>， 需要将所有数据集运算一遍，来获得错误率。</p>]]></content><author><name></name></author><category term="machinelearning" /><category term="deeplearning" /><category term="math" /><summary type="html"><![CDATA[感知机 感知器假设集（Perceptron Hypothesis Set） 感知器算法: \(h(x)=sign((\sum_{i=1}^dw_ix_i)-threshold)\) 对上面的公示进行变形，将threshold作为偏置，纳入 x 中，\(x_0=+1\) ; \[h(x)=sign(W^TX)\] 每一个不同的W代表了算法中的一个hypothesis. PLA 感知器学习算法 要从 hypothesis set 中找到一个合适的 hypothesis g, 让 g 与目标函数 f 尽可能的相近。 PLA算法通过试错的方法实现模型的训练： 总共进行t轮的训练， t=0, 1, … 随机初始化 \(w_0\); 将样本 \((x_{n(t)},y_{n(t)})\) 带入PLA学习机， 如果： \[sign(w^T_tx_{n(t)})\neq y_{n(t)}\] 那么，表示发生错误，需要对错误进行纠正。 修正错误： \[w_{t+1} \leftarrow w_t + y_{n(t)}x_{n(t)}\] \(w\): 代表分类线的法向量 \(x_n\): 是原点到 \(x_n\) 的向量 当 \(y_n = +1\), 将 \(w\) 的方向向样本 \((x_n, y_n)\) 的方向转动。 当 \(y_n = -1\), 将\(w\)的方向向样本 \((x_n, y_n)\) 的反方向转动。 当不再出现错误的时候，训练结束。 PLA算法要能终止，要求训练数据集必须是线性可分的 \(w_t\) 越来越接近 \(w_f\) \(w_f\): 目标函数 f 对应的参数，因此对于任意一个样本，它都能正确的分类： \[y_{n(t)}w^T_fx_{n(t)} \ge \min_ny_nw^T_fx_n \gt 0\] 衡量两个向量是否接近，可以用它们的内积，如果内积越小代表它们越不接近，相互垂直时为 0 \[\begin{align} \begin{split} w_f^Tw_{t+1} &amp;= w_f^T(w_t+y_{n(t)}x_{n(t)}) \\ &amp;\ge w_f^Tw_t + \min_ny_nw_f^Tx_n \\ &amp;\gt w_f^Tw_t + 0 \end{split} \end{align}\] \(w_t\) 的增长速率不快 \(w_t\)每次的更新不超过离分割线最远的样本的距离 \(w_t\) 的每次更新发生在有错误的时候： \[sign(w_t^fx_{n(t)}) \neq y_{n(t)} \Leftrightarrow y_{n(t)}w_t^Tx_{n(t)} \leq 0\] 对于每一次更新后的结果： \[\begin{equation}\begin{split} ||w_{t+1}||^2 &amp;= ||w_t + y_{n(t)}x_{n(t)}||^2\\\\ &amp;= ||w_t||^2 + 2y_{n(t)}w_t^Tx_{n(t)} + ||y_{n(t)}x_{n(t)}||^2\\\\ &amp;\le ||w_t||^2 + 0 + ||y_{n(t)x_{n(t)}}||^2\\\\ &amp;\le ||w_t||^2 + \max_n||y_{n(t)}x_{n(t)}||^2\end{split}\end{equation}\] 其中 \(\max_n \Vert y_{n(t)}x_{n(t)} \Vert ^2\) 就代表了距离到分隔线最远的点的距离。 \[\begin{equation}\begin{split} \text{start from w_0 = 0, after T mistake corrections,} \\ \frac{w_f^T}{\Vert w_f \Vert} \frac{w_T}{\Vert w_T \Vert} \ge \sqrt T * \text{constant} \end{split}\end{equation}\] \(w_f^Tw_{t+1}\) 的内积是小于等于1的，再根据上面的式子，知道T不可能为无穷大，所以运算会终止。 Pocket 算法 算法步骤 随机初始化 w 进行 t 轮的学习， t = 0, 1, … 如果发生错误，按照 PLA 算法对 w进行纠正：\(w_{t+1} \leftarrow w_t + y_{n(t)}x_{n(t)}\) 判断对比纠正后的算法与之前算法的错误率，如果更好，者保留新的wt+1, 否者保留之前的w。 运算足够多次之后停止运算。 Pocket算法是PLA的改进算法，用于解决线性不可分的数据集。 Pocket算法的运算量大：对于比PLA，在得到新的wt+1， 需要将所有数据集运算一遍，来获得错误率。]]></summary></entry><entry><title type="html">软件设计模型-功能开关</title><link href="http://localhost:4000/designpattern/softwareengineering/2020/04/20/Feature-Toggles.html" rel="alternate" type="text/html" title="软件设计模型-功能开关" /><published>2020-04-20T17:26:21+08:00</published><updated>2020-04-20T17:26:21+08:00</updated><id>http://localhost:4000/designpattern/softwareengineering/2020/04/20/Feature-Toggles</id><content type="html" xml:base="http://localhost:4000/designpattern/softwareengineering/2020/04/20/Feature-Toggles.html"><![CDATA[<h2 id="功能开关">功能开关</h2>
<p>本文受到 Pete Hodgson 的文章 <a href="https://www.martinfowler.com/articles/feature-toggles.html">Feature Toggles (aka Feature Flags)</a> 启发，原文内容比本文更加丰富。</p>

<h3 id="简单的功能开关">简单的功能开关</h3>

<p>场景一：你刚刚开发完一个新的功能，然后需求告诉你，由于这个功能使用场景的限制，需要添加一个开关，能够让这个功能在某些环境打开或者关闭。</p>

<p>场景二：你实现了一个新版本的算法，但是并不希望立刻在线上启用，希望能进行更多的测试，所以需要添加一个开关，在测试环境打开，在生产环境保持关闭。</p>

<p>这个时候你只需要实现一个简单的功能开关即可。</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">func</span> <span class="n">doSomeThing</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">useNewAlgorithm</span> <span class="o">:=</span> <span class="no">false</span>
    <span class="c">// useNewAlgorithm := true // uncomment if you working with new algorithm</span>
    <span class="k">if</span> <span class="n">useNewAlgoritem</span> <span class="p">{</span>
        <span class="n">doSomeThingNew</span><span class="p">()</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="n">doSomeThingOld</span><span class="p">()</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">func</span> <span class="n">doSomeThingNew</span><span class="p">()</span> <span class="p">{</span>
    <span class="c">// implement something new</span>
<span class="p">}</span>

<span class="k">func</span> <span class="n">doSomeThingOld</span><span class="p">()</span> <span class="p">{</span>
    <span class="c">// implement something old</span>
<span class="p">}</span>

</code></pre></div></div>

<p>我们把新的功能写到 <code>doSomeThingNew</code> 函数中，并通过 <code>useNewAlgorithm</code> 变量来控制是否调用新功能。这个方法虽然简单，但是我们无法在运行时动态的去决定是否启用新的功能。为了实现对于新功能的动态控制，我们可以引入一个<strong>开关路由器</strong>（toggle router）来实现。</p>

<h3 id="开关路由器">开关路由器</h3>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">type</span> <span class="n">ToggleRouter</span> <span class="k">struct</span> <span class="p">{</span>
	<span class="n">featureConfig</span> <span class="k">map</span><span class="p">[</span><span class="kt">string</span><span class="p">]</span><span class="k">struct</span><span class="p">{}</span>
<span class="p">}</span>

<span class="k">func</span> <span class="p">(</span><span class="n">tr</span> <span class="o">*</span><span class="n">ToggleRouter</span><span class="p">)</span> <span class="n">SetFeature</span><span class="p">(</span><span class="n">featureName</span> <span class="kt">string</span><span class="p">,</span> <span class="n">isEnabled</span> <span class="kt">bool</span><span class="p">)</span> <span class="p">{</span>
	<span class="k">if</span> <span class="n">isEnabled</span> <span class="p">{</span>
		<span class="n">tr</span><span class="o">.</span><span class="n">featureConfig</span><span class="p">[</span><span class="n">featureName</span><span class="p">]</span> <span class="o">=</span> <span class="k">struct</span><span class="p">{}{}</span>
	<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
		<span class="nb">delete</span><span class="p">(</span><span class="n">tr</span><span class="o">.</span><span class="n">featureConfig</span><span class="p">,</span> <span class="n">featureName</span><span class="p">)</span>
	<span class="p">}</span>
<span class="p">}</span>

<span class="k">func</span> <span class="p">(</span><span class="n">tr</span> <span class="o">*</span><span class="n">ToggleRouter</span><span class="p">)</span> <span class="n">IsFeatureEnabled</span><span class="p">(</span><span class="n">featureName</span> <span class="kt">string</span><span class="p">)</span> <span class="kt">bool</span> <span class="p">{</span>
	<span class="n">_</span><span class="p">,</span> <span class="n">ok</span> <span class="o">:=</span> <span class="n">tr</span><span class="o">.</span><span class="n">featureConfig</span><span class="p">[</span><span class="n">featureName</span><span class="p">]</span>
	<span class="k">return</span> <span class="n">ok</span>
<span class="p">}</span>

<span class="k">func</span> <span class="n">NewToggleRouter</span><span class="p">(</span><span class="n">features</span> <span class="p">[]</span><span class="kt">string</span><span class="p">)</span> <span class="p">(</span><span class="n">tr</span> <span class="o">*</span><span class="n">ToggleRouter</span><span class="p">)</span> <span class="p">{</span>
	<span class="n">tr</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">ToggleRouter</span><span class="p">{</span>
		<span class="n">featureConfig</span><span class="o">:</span> <span class="nb">make</span><span class="p">(</span><span class="k">map</span><span class="p">[</span><span class="kt">string</span><span class="p">]</span><span class="k">struct</span><span class="p">{}),</span>
	<span class="p">}</span>

	<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">feat</span> <span class="o">:=</span> <span class="k">range</span> <span class="n">features</span> <span class="p">{</span>
		<span class="n">tr</span><span class="o">.</span><span class="n">SetFeature</span><span class="p">(</span><span class="n">feat</span><span class="p">,</span> <span class="no">true</span><span class="p">)</span>
	<span class="p">}</span>

	<span class="k">return</span>
<span class="p">}</span>

<span class="k">var</span> <span class="n">toggleRouter</span> <span class="o">=</span> <span class="n">NewToggleRouter</span><span class="p">([]</span><span class="kt">string</span><span class="p">{</span><span class="s">"newAlgo"</span><span class="p">})</span>

<span class="k">func</span> <span class="n">doSomeThing</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">if</span> <span class="n">toggleRouter</span><span class="o">.</span><span class="n">IsFeatureEnabled</span><span class="p">(</span><span class="s">"newAlgo"</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">doSomeThingNew</span><span class="p">()</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="n">doSomeThingOld</span><span class="p">()</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>通过开关路由器我们可以动态的设置功能的启用与否。ToggleRouter 可以通过配置文件创建，或者通过配置界面，或者 API 接口来进行配置。到现在问题似乎已经解决了，然而随着越来越多的新功能加入，越来越多的功能需要通过开关来配置是否开启，代码中出现了越来越多的<strong>开关点</strong>，代码也变得越来越难以理解和维护。</p>

<p>让我们看一个新例子，<code>InvoiceEmailler</code> 会根据收据发送一封电子邮件，现在我们希望能加上一个新的功能，在邮件中添加退货链接。而这个退货链接只是在特定的情况下才会触发。下面代码中是根据 开关中是否包含 <code>next-gen-ecomm</code> 来判断的。</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">var</span> <span class="n">toggle</span> <span class="o">=</span> <span class="n">GetFeatureToggleRouter</span><span class="p">()</span>

<span class="k">type</span> <span class="n">InvoiceEmailler</span> <span class="k">struct</span> <span class="p">{</span>
    <span class="n">invoice</span> <span class="n">Invoice</span>
<span class="p">}</span>

<span class="k">func</span> <span class="p">(</span><span class="n">emailler</span> <span class="o">*</span><span class="n">InvoiceEmailler</span><span class="p">)</span> <span class="n">GenerateInvoiceEmail</span><span class="p">()</span> <span class="n">Email</span> <span class="p">{</span>
    <span class="n">baseEmail</span> <span class="o">:=</span> <span class="n">buildEmailForInvoice</span><span class="p">(</span><span class="n">emailler</span><span class="o">.</span><span class="n">invoice</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">toggle</span><span class="o">.</span><span class="n">IsFeatureEnabled</span><span class="p">(</span><span class="s">"next-gen-ecomm"</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">addOrderCallationContentToEmail</span><span class="p">(</span><span class="n">baseEmail</span><span class="p">)</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">baseEmail</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>但是，对于一个功能是否启用的判断逻辑可能是十分复杂的，也许在 A 情况下需要开启，在 B 情况下需要关闭；或者需要对某一部分用户开启这一项功能，对另一部分用户关闭这一功能；开关的判断逻辑可能会频繁的迭代。如果要更新判断逻辑，我们不得不在每个开关点去修改判断逻辑。这是代码中的第一个问题：<strong>开关点与开关的判断逻辑耦合在一起</strong>。</p>

<h3 id="解耦开关点与开关路由器">解耦开关点与开关路由器</h3>

<p>幸好<a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_software_engineering">“软件中的任何问题都可以通过引入一个间接层来解决”</a>, 通过增加一个<strong>开关逻辑判断层</strong>我们可以解耦开关点与开关判断逻辑。</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">type</span> <span class="n">FeatureDecisions</span> <span class="k">struct</span> <span class="p">{</span>
    <span class="n">toggle</span> <span class="o">*</span><span class="n">ToggleRouter</span>
<span class="p">}</span>

<span class="k">func</span> <span class="p">(</span><span class="n">descisions</span> <span class="o">*</span><span class="n">FeatureDecisions</span><span class="p">)</span> <span class="n">IncludeOrderCancellationInEmail</span><span class="p">()</span> <span class="kt">bool</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">descisions</span><span class="o">.</span><span class="n">toggle</span><span class="o">.</span><span class="n">IsFeatureEnabled</span><span class="p">(</span><span class="s">"new-gen-ecomm"</span><span class="p">)</span>
<span class="p">}</span>

<span class="k">func</span> <span class="n">NewFeatureDecisions</span><span class="p">(</span><span class="n">toggle</span> <span class="o">*</span><span class="n">ToggleRouter</span><span class="p">)</span> <span class="n">FeatureDecisions</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">FeatureDecisions</span><span class="p">{</span><span class="n">toggle</span><span class="o">:</span> <span class="n">toggle</span><span class="p">}</span>
<span class="p">}</span>


<span class="k">var</span> <span class="n">toggle</span> <span class="o">=</span> <span class="n">GetFeatureToggleRouter</span><span class="p">()</span>
<span class="k">var</span> <span class="n">featureDecisions</span> <span class="o">=</span> <span class="n">NewFeatureDecision</span><span class="p">(</span><span class="n">toggle</span><span class="p">)</span>

<span class="k">type</span> <span class="n">InvoiceEmailler</span> <span class="k">struct</span> <span class="p">{</span>
    <span class="n">invoice</span> <span class="n">Invoice</span>
<span class="p">}</span>

<span class="k">func</span> <span class="p">(</span><span class="n">emailler</span> <span class="o">*</span><span class="n">InvoiceEmailler</span><span class="p">)</span> <span class="n">GenerateInvoiceEmail</span><span class="p">()</span> <span class="n">Email</span> <span class="p">{</span>
    <span class="n">baseEmail</span> <span class="o">:=</span> <span class="n">buildEmailForInvoice</span><span class="p">(</span><span class="n">emailler</span><span class="o">.</span><span class="n">invoice</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">featureDecisions</span><span class="o">.</span><span class="n">IncludeOrderCancellationInEmail</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">addOrderCallationContentToEmail</span><span class="p">(</span><span class="n">baseEmail</span><span class="p">)</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">baseEmail</span>
    <span class="p">}</span>
<span class="p">}</span>

</code></pre></div></div>

<p>通过引入 <code>FeatureDecisions</code> 之后，<code>InvoiceEmailler</code> 不再关心添加退货链接的逻辑是什么；而后续对与添加退货链接逻辑的更新也与 <code>InvoiceEmailler</code> 无关。从而实现了<strong>开关点与开关判断逻辑的解耦</strong>。</p>

<h3 id="判断翻转inversion-of-decision">判断翻转(Inversion of Decision)</h3>

<p>虽然在上一步中，我们通过添加<strong>判断逻辑层</strong>实现了判断逻辑与开关点的解耦，但是 <code>InvoiceEmailler</code> 依旧与 <code>FeatureDecisions</code> 耦合在一起，在执行 <code>GenerateInvoiceEmail()</code> 需要先创建或者获取 <code>FeatureDecisions</code> ，这处代码“坏味道”带来了两个问题：</p>

<ol>
  <li>它不方便对代码进行测试，在测试 <code>GenerateInvoiceEmail()</code> 函数之前，我们必须先设置好调用 <code>GetFeatureToggleRouter()</code> 与 <code>NewFeatureDecision()</code> 函数的环境，才能确保可以到达待测试逻辑代码块。</li>
  <li>随着项目功能模块的增多，每个模块都与 <code>FeatureDecisions</code> 模块发生了耦合，使得该模块变成了全局依赖模块。</li>
</ol>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">// invoice_emailler.go</span>

<span class="k">type</span> <span class="n">EmaillerDecisions</span> <span class="k">interface</span> <span class="p">{</span>
    <span class="n">IncludeOrderCancellationInEmail</span><span class="p">()</span> <span class="kt">bool</span>
<span class="p">}</span>

<span class="k">type</span> <span class="n">InvoiceEmailler</span> <span class="k">struct</span> <span class="p">{</span>
    <span class="n">invoice</span> <span class="n">Invoice</span>
    <span class="n">decisions</span> <span class="n">EmaillerDecisions</span>
<span class="p">}</span>

<span class="k">func</span> <span class="p">(</span><span class="n">emailler</span> <span class="o">*</span><span class="n">InvoiceEmailler</span><span class="p">)</span> <span class="n">SetDecisions</span><span class="p">(</span><span class="n">decisions</span> <span class="o">*</span><span class="n">FeatureDecisions</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">emailler</span><span class="o">.</span><span class="n">decisions</span> <span class="o">=</span> <span class="n">decisions</span>
<span class="p">}</span>

<span class="k">func</span> <span class="p">(</span><span class="n">emailler</span> <span class="o">*</span><span class="n">InvoiceEmailler</span><span class="p">)</span> <span class="n">GenerateInvoiceEmail</span><span class="p">()</span> <span class="n">Email</span> <span class="p">{</span>
    <span class="n">baseEmail</span> <span class="o">:=</span> <span class="n">buildEmailForInvoice</span><span class="p">(</span><span class="n">emailler</span><span class="o">.</span><span class="n">invoice</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">emailler</span><span class="o">.</span><span class="n">decisions</span><span class="o">.</span><span class="n">includeOrderCancellationInEmail</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">addOrderCallationContentToEmail</span><span class="p">(</span><span class="n">baseEmail</span><span class="p">)</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">baseEmail</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c">// inject decisions module</span>
<span class="k">func</span> <span class="n">NewInvoiceEmailler</span><span class="p">(</span><span class="n">decisions</span> <span class="n">EmaillerDecisions</span><span class="err">，</span> <span class="n">invoice</span> <span class="n">Invoice</span><span class="p">)</span> <span class="o">*</span><span class="n">InvoiceEmailler</span> <span class="p">{</span>
    <span class="k">return</span> <span class="o">&amp;</span><span class="n">InvoiceEmailler</span><span class="p">{</span>
        <span class="n">invoice</span><span class="o">:</span> <span class="n">invoice</span><span class="p">,</span>
        <span class="n">decisions</span><span class="o">:</span> <span class="n">decisions</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">}</span>

</code></pre></div></div>

<p>此处“坏味道”的根本原因是业务模块对 <code>FeatureDecisions</code> 模块的依赖，通过<strong>控制反转</strong>在 <code>InvoiceEmailler</code> 模块创建时，将 <code>FeatureDecisions</code> 注入到 <code>InvoiceEmailler</code> 中，就可以消除业务模块对与 <code>FeatureDecisions</code> 模块的依赖。</p>

<h3 id="消除条件判断">消除条件判断</h3>

<p>到现在位置我们代码已经获得了很大优化，那我们能不能在进一步消除 <code>GenerateInvoiceEmail()</code> 函数的条件判断呢？ 对于简单的场景下的条件判断语句是没有什么问题的，但是在复杂的业务逻辑中，太多的条件判断并不利于代码的维护。比如如果配置中包含 feature “after-sales-service”,  需要在 email 中添加售后服务的信息。现在我们必须回到  <code>GenerateInvoiceEmail()</code>，修改判断条件再加上添加售后服务的信息。</p>

<p>通过策略模式，我们可以进一步的消除业务代码中的逻辑判断，提升代码的可扩展性。</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">type</span> <span class="n">EmaillerDecisions</span> <span class="k">interface</span> <span class="p">{</span>
	<span class="n">IncludeOrderCancellationInEmail</span><span class="p">()</span> <span class="kt">bool</span>

	<span class="n">IncludeAfterSalesServiceInEmail</span><span class="p">()</span> <span class="kt">bool</span>
<span class="p">}</span>

<span class="k">type</span> <span class="n">AdditionalContentEnhancer</span> <span class="k">interface</span> <span class="p">{</span>
	<span class="n">EnhanceContent</span><span class="p">(</span><span class="n">Email</span><span class="p">)</span> <span class="n">Email</span>
<span class="p">}</span>

<span class="k">type</span> <span class="n">InvoiceEmailler</span> <span class="k">struct</span> <span class="p">{</span>
	<span class="n">invoice</span>  <span class="n">Invoice</span>
	<span class="n">enhancer</span> <span class="n">AdditionalContentEnhancer</span>
<span class="p">}</span>

<span class="k">func</span> <span class="p">(</span><span class="n">emailler</span> <span class="o">*</span><span class="n">InvoiceEmailler</span><span class="p">)</span> <span class="n">GenerateInvoiceEmail</span><span class="p">()</span> <span class="n">Email</span> <span class="p">{</span>
	<span class="n">baseEmail</span> <span class="o">:=</span> <span class="n">buildEmailForInvoice</span><span class="p">(</span><span class="n">emailler</span><span class="o">.</span><span class="n">invoice</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">enhancer</span><span class="o">.</span><span class="n">EnhanceContent</span><span class="p">(</span><span class="n">baseEmail</span><span class="p">)</span>
<span class="p">}</span>

<span class="k">type</span> <span class="n">OrderCallationContentEnhancer</span> <span class="k">struct</span><span class="p">{}</span>

<span class="k">func</span> <span class="p">(</span><span class="n">e</span> <span class="n">OrderCallationContentEnhancer</span><span class="p">)</span> <span class="n">addOrderCallationContentToEmail</span><span class="p">(</span><span class="n">email</span> <span class="n">Email</span><span class="p">)</span> <span class="p">(</span><span class="n">newEmail</span> <span class="n">Email</span><span class="p">)</span> <span class="p">{</span>
	<span class="c">// implement addOrderCallationContentToEmail</span>
	<span class="k">return</span>
<span class="p">}</span>

<span class="k">func</span> <span class="p">(</span><span class="n">e</span> <span class="n">OrderCallationContentEnhancer</span><span class="p">)</span> <span class="n">EnhanceContent</span><span class="p">(</span><span class="n">email</span> <span class="n">Email</span><span class="p">)</span> <span class="n">Email</span> <span class="p">{</span>
	<span class="k">return</span> <span class="n">e</span><span class="o">.</span><span class="n">addOrderCallationContentToEmail</span><span class="p">(</span><span class="n">email</span><span class="p">)</span>
<span class="p">}</span>

<span class="k">type</span> <span class="n">AfterSalesServiceContentEnhancer</span> <span class="k">struct</span><span class="p">{}</span>

<span class="k">func</span> <span class="p">(</span><span class="n">e</span> <span class="n">AfterSalesServiceContentEnhancer</span><span class="p">)</span> <span class="n">addAfterSalesServiceContentToEmail</span><span class="p">(</span><span class="n">email</span> <span class="n">Email</span><span class="p">)</span> <span class="p">(</span><span class="n">newEmail</span> <span class="n">Email</span><span class="p">)</span> <span class="p">{</span>
	<span class="c">// implement addAfterSalesServiceContentToEmail</span>
	<span class="k">return</span>
<span class="p">}</span>

<span class="k">func</span> <span class="p">(</span><span class="n">e</span> <span class="n">AfterSalesServiceContentEnhancer</span><span class="p">)</span> <span class="n">EnhanceContent</span><span class="p">(</span><span class="n">email</span> <span class="n">Email</span><span class="p">)</span> <span class="n">Email</span> <span class="p">{</span>
	<span class="k">return</span> <span class="n">e</span><span class="o">.</span><span class="n">addAfterSalesServiceContentToEmail</span><span class="p">(</span><span class="n">email</span><span class="p">)</span>
<span class="p">}</span>

<span class="k">type</span> <span class="n">OrderCallationAndAfterSalesServiceContentEnhancer</span> <span class="k">struct</span> <span class="p">{</span>
	<span class="n">OrderCallationContentEnhancer</span>
	<span class="n">AfterSalesServiceContentEnhancer</span>
<span class="p">}</span>

<span class="k">func</span> <span class="p">(</span><span class="n">e</span> <span class="n">OrderCallationAndAfterSalesServiceContentEnhancer</span><span class="p">)</span> <span class="n">EnhanceContent</span><span class="p">(</span><span class="n">email</span> <span class="n">Email</span><span class="p">)</span> <span class="n">Email</span> <span class="p">{</span>
	<span class="n">email</span> <span class="o">=</span> <span class="n">e</span><span class="o">.</span><span class="n">OrderCallationContentEnhancer</span><span class="o">.</span><span class="n">EnhanceContent</span><span class="p">(</span><span class="n">email</span><span class="p">)</span>
	<span class="n">email</span> <span class="o">=</span> <span class="n">e</span><span class="o">.</span><span class="n">AfterSalesServiceContentEnhancer</span><span class="o">.</span><span class="n">EnhanceContent</span><span class="p">(</span><span class="n">email</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">email</span>
<span class="p">}</span>

<span class="k">type</span> <span class="n">IdentityContentEnhancer</span> <span class="k">struct</span><span class="p">{}</span>

<span class="k">func</span> <span class="p">(</span><span class="n">e</span> <span class="n">IdentityContentEnhancer</span><span class="p">)</span> <span class="n">EnhanceContent</span><span class="p">(</span><span class="n">email</span> <span class="n">Email</span><span class="p">)</span> <span class="n">Email</span> <span class="p">{</span>
	<span class="k">return</span> <span class="n">email</span>
<span class="p">}</span>

<span class="c">// inject decisions module</span>
<span class="k">func</span> <span class="n">NewInvoiceEmailler</span><span class="p">(</span><span class="n">decisions</span> <span class="n">EmaillerDecisions</span><span class="p">,</span> <span class="n">invoice</span> <span class="n">Invoice</span><span class="p">)</span> <span class="o">*</span><span class="n">InvoiceEmailler</span> <span class="p">{</span>
	<span class="n">emailler</span> <span class="o">:=</span> <span class="o">&amp;</span><span class="n">InvoiceEmailler</span><span class="p">{</span>
		<span class="n">invoice</span><span class="o">:</span> <span class="n">invoice</span><span class="p">,</span>
	<span class="p">}</span>

	<span class="k">if</span> <span class="n">decisions</span><span class="o">.</span><span class="n">IncludeOrderCancellationInEmail</span><span class="p">()</span> <span class="o">&amp;&amp;</span> <span class="n">decisions</span><span class="o">.</span><span class="n">IncludeAfterSalesServiceInEmail</span><span class="p">()</span> <span class="p">{</span>
		<span class="n">emailler</span><span class="o">.</span><span class="n">enhancer</span> <span class="o">=</span> <span class="n">OrderCallationAndAfterSalesServiceContentEnhancer</span><span class="p">{}</span>
	<span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="n">decisions</span><span class="o">.</span><span class="n">IncludeOrderCancellationInEmail</span><span class="p">()</span> <span class="p">{</span>
		<span class="n">emailler</span><span class="o">.</span><span class="n">enhancer</span> <span class="o">=</span> <span class="n">OrderCallationContentEnhancer</span><span class="p">{}</span>
	<span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="n">decisions</span><span class="o">.</span><span class="n">IncludeAfterSalesServiceInEmail</span><span class="p">()</span> <span class="p">{</span>
		<span class="n">emailler</span><span class="o">.</span><span class="n">enhancer</span> <span class="o">=</span> <span class="n">AfterSalesServiceContentEnhancer</span><span class="p">{}</span>
	<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
		<span class="n">emailler</span><span class="o">.</span><span class="n">enhancer</span> <span class="o">=</span> <span class="n">IdentityContentEnhancer</span><span class="p">{}</span>
	<span class="p">}</span>

	<span class="k">return</span>
<span class="p">}</span>

</code></pre></div></div>

<p>到现在我们就差不多完成了对于代码的优化。</p>]]></content><author><name></name></author><category term="designpattern" /><category term="softwareengineering" /><summary type="html"><![CDATA[功能开关 本文受到 Pete Hodgson 的文章 Feature Toggles (aka Feature Flags) 启发，原文内容比本文更加丰富。]]></summary></entry><entry><title type="html">Python 依赖管理软件 Poetry 上手</title><link href="http://localhost:4000/designpattern/softwareengineering/2020/04/20/Python-Poetry-In-Action.html" rel="alternate" type="text/html" title="Python 依赖管理软件 Poetry 上手" /><published>2020-04-20T17:26:21+08:00</published><updated>2020-04-20T17:26:21+08:00</updated><id>http://localhost:4000/designpattern/softwareengineering/2020/04/20/Python-Poetry-In-Action</id><content type="html" xml:base="http://localhost:4000/designpattern/softwareengineering/2020/04/20/Python-Poetry-In-Action.html"><![CDATA[<h2 id="python-项目管理-poetry-上手">Python 项目管理 Poetry 上手</h2>

<p>Python 项目依赖管理工具有 virtualenv pipenv anaconda，来帮助项目做到项目之间的环境隔离，依赖管理等。今天介绍的 Poetry 是它更像是 Python 项目 CLI 工具，能够进行项目模板创建，依赖管理，项目构建与发布等。Poetry v0.1.0 版本发布2018-02，到现在两年的时间，目前社区比较活跃。</p>

<h3 id="poetry-配置">Poetry 配置</h3>

<h4 id="1--安装">1  安装</h4>

<p>OSX / Linux / bashonwindows 使用脚本自动安装</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-sSL</span> https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py | python
</code></pre></div></div>

<p>在类 *nix 的系统中 Poetry 会默认安装在 <code>$HOME/.poetry/bin </code> 中， 在window系统下默认安装目录为 <code>%USERPROFILE%\.poetry\bin</code>。</p>

<p>如果要修改安装目录，需要在运行安装脚本时通过环境变量 <code>POETRY_HOME</code> 来指定。 使用参数 <code>--version</code> 或者环境变量 <code>POETRY_VERSION</code> 可以指定安装版本。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">POETRY_HOME</span><span class="o">=</span>/etc/poetry python get-poetry.py <span class="nt">--version</span> 1.0.5
</code></pre></div></div>

<h4 id="2-安装检查">2. 安装检查</h4>

<p>安装成功后检查 poetry 版本</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>poetry <span class="nt">--version</span>
</code></pre></div></div>

<p>如果无法找到  <code>poetry</code> 命令， 那么记得把安装目录加到 $PATH 中。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export</span> <span class="nv">$PATH</span><span class="o">=</span><span class="nv">$HOME</span>/.poetry/bin:<span class="nv">$PATH</span>
</code></pre></div></div>

<h4 id="3更新卸载-poetry">3.更新&amp;卸载 Poetry</h4>

<p>更新 Poetry</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 更新到最新的稳定版本</span>
poetry self update

<span class="c"># 更新到预览版本</span>
poetry self udpate <span class="nt">--preview</span>

<span class="c"># 更新到指定版本</span>
poetry self update 1.0.5
</code></pre></div></div>

<p>卸载 Poetry</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python get-poetry.py <span class="nt">--uninstall</span>
</code></pre></div></div>

<h3 id="基本用法">基本用法</h3>]]></content><author><name></name></author><category term="designpattern" /><category term="softwareengineering" /><summary type="html"><![CDATA[Python 项目管理 Poetry 上手]]></summary></entry><entry><title type="html">Large Kernel Matters - Improve Semantic Segmentation by Global Convolutional Network</title><link href="http://localhost:4000/machinelearning/deeplearning/math/2019/07/29/Large-Kernel-Matters-Improve-Semantic-Segmentation-by-Global-Convolutional-Network.html" rel="alternate" type="text/html" title="Large Kernel Matters - Improve Semantic Segmentation by Global Convolutional Network" /><published>2019-07-29T17:26:21+08:00</published><updated>2019-07-29T17:26:21+08:00</updated><id>http://localhost:4000/machinelearning/deeplearning/math/2019/07/29/Large-Kernel-Matters-Improve-Semantic-Segmentation-by-Global-Convolutional-Network</id><content type="html" xml:base="http://localhost:4000/machinelearning/deeplearning/math/2019/07/29/Large-Kernel-Matters-Improve-Semantic-Segmentation-by-Global-Convolutional-Network.html"><![CDATA[<p><strong>论文题目:</strong> Large Kernel Matters - Improve Semantic Segmentation by Global Convolutional Network</p>

<p><strong>论文内容:</strong> 使用全局卷积网络(GCN)解决分割模型中分类与分割任务冲突的问题，使用Boundary Refinement block 提升物体边缘的分割能力。</p>

<h1 id="论文亮点">论文亮点</h1>

<blockquote>
  <ol>
    <li>Classification and localization are two naturally contradictory tasks. For the classification task, the models are required to be invariant to various transformations like translation and rotation. But for localization task, models should be transformation-sensitive, precisely locate every pixel for each semantic category.</li>
  </ol>
</blockquote>

<h1 id="approach">Approach</h1>

<h2 id="global-convolutional-network">Global Convolutional Network</h2>

<p>GCN 的目的是同时满足在分割网络中对于分类和定位的需求。从定位任务的要求来说网络结构是一个不包含全连接和全局池化的全卷积结构，因为全局池化会抹去定位信息；从分类角度来说网络需要稠密连接结构，所以卷积核的尺寸应该尽可能的大。</p>

<p><img src="/assets/1560924841688.png" alt="1560924841688" /></p>

<p>GCN中使用 1×k + k×1 的卷积核来代替 k×k的卷积核降低计算量。</p>

<h2 id="boundary-refinement">Boundary Refinement</h2>

<p>BR 块是一种残差结构，用于优化物体边缘分割的能力</p>

<p><img src="/assets/1560925157354.png" alt="1560925157354" /></p>]]></content><author><name></name></author><category term="machinelearning" /><category term="deeplearning" /><category term="math" /><summary type="html"><![CDATA[论文题目: Large Kernel Matters - Improve Semantic Segmentation by Global Convolutional Network]]></summary></entry><entry><title type="html">On large-batch training for deep leanring: generalization gap and sharp minima 笔记</title><link href="http://localhost:4000/machinelearning/deeplearning/math/2019/07/29/On-large-batch-training-for-deep-learning-generalization-gap-and-sharp-minima.html" rel="alternate" type="text/html" title="On large-batch training for deep leanring: generalization gap and sharp minima 笔记" /><published>2019-07-29T17:26:21+08:00</published><updated>2019-07-29T17:26:21+08:00</updated><id>http://localhost:4000/machinelearning/deeplearning/math/2019/07/29/On-large-batch-training-for-deep-learning-generalization-gap-and-sharp-minima</id><content type="html" xml:base="http://localhost:4000/machinelearning/deeplearning/math/2019/07/29/On-large-batch-training-for-deep-learning-generalization-gap-and-sharp-minima.html"><![CDATA[<p><strong>论文题目:</strong> On large-batch training for deep leanring: generalization gap and sharp minima</p>

<p><strong>论文内容：</strong> 在SGD中使用较大的batch-size会导致模型的泛化能力退化，因为较大的batch size 模型更加容易在 sharp minima处收敛，较小的batch size使模型在 flat minima处收敛。</p>

<p><strong>论文亮点</strong></p>

<blockquote>
  <p>Many theoretical properties of these methods (SGD and its variants) are known. These include guarantees of:</p>

  <p>(a) convergence to minimizers of strongly-convex functions and to stationary points for non-convex functions,</p>

  <p>(b) saddle-point avoidance and</p>

  <p>(c) robustness to input data.</p>

  <p>Stochastic gradient methods have, however, a major drawback: owing to the sequential nature of the iteration and small batch sizes, there is limited avenue for parallelization.</p>
</blockquote>

<h3 id="大-batch-size-的缺点">大 batch size 的缺点</h3>

<p>大 batch size 的泛化能力差是因为，它倾向收敛在 sharp minima 处。 极小值的 sharpness 是由 \(\nabla ^2 f(x)\) 正特征值的大小来决定的，特征值越大，极小值就越 sharp， 泛化能力也就越差。</p>]]></content><author><name></name></author><category term="machinelearning" /><category term="deeplearning" /><category term="math" /><summary type="html"><![CDATA[论文题目: On large-batch training for deep leanring: generalization gap and sharp minima]]></summary></entry><entry><title type="html">Population based Augmentation: Efficient Learning of Augmentation Policy Schedules 笔记</title><link href="http://localhost:4000/machinelearning/deeplearning/math/2019/07/29/Population-based-Augmentation.html" rel="alternate" type="text/html" title="Population based Augmentation: Efficient Learning of Augmentation Policy Schedules 笔记" /><published>2019-07-29T17:26:21+08:00</published><updated>2019-07-29T17:26:21+08:00</updated><id>http://localhost:4000/machinelearning/deeplearning/math/2019/07/29/Population-based-Augmentation</id><content type="html" xml:base="http://localhost:4000/machinelearning/deeplearning/math/2019/07/29/Population-based-Augmentation.html"><![CDATA[<p><strong>论文名称：</strong> Population based Augmentation: Efficient Learning of Augmentation Policy Schedules</p>]]></content><author><name></name></author><category term="machinelearning" /><category term="deeplearning" /><category term="math" /><summary type="html"><![CDATA[论文名称： Population based Augmentation: Efficient Learning of Augmentation Policy Schedules]]></summary></entry></feed>