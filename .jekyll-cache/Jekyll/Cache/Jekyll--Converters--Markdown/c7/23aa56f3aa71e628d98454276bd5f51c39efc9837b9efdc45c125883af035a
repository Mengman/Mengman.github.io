I"Q<h1 id="感知机">感知机</h1>

<h2 id="感知器假设集perceptron-hypothesis-set">感知器假设集（Perceptron Hypothesis Set）</h2>
<p>感知器算法:  \(h(x)=sign((\sum_{i=1}^dw_ix_i)-threshold)\)</p>

<p>对上面的公示进行变形，将<strong>threshold</strong>作为偏置，纳入 x 中，\(x_0=+1\) ;</p>

<p>[h(x)=sign(W^TX)]</p>

<p>每一个不同的W代表了算法中的一个hypothesis.</p>

<h2 id="pla-感知器学习算法">PLA 感知器学习算法</h2>

<p>要从 hypothesis set 中找到一个合适的 hypothesis g, 让 g 与目标函数 f 尽可能的相近。</p>

<p>PLA算法通过试错的方法实现模型的训练：</p>

<p>总共进行t轮的训练， t=0, 1, …</p>

<ol>
  <li>
    <p>随机初始化 \(w_0\);</p>
  </li>
  <li>
    <p>将样本 \((x_{n(t)},y_{n(t)})\) 带入PLA学习机， 如果：</p>
  </li>
</ol>

<p>[sign(w^T_tx_{n(t)})\neq y_{n(t)}]</p>

<p>那么，表示发生错误，需要对错误进行纠正。</p>

<ol>
  <li>
    <p>修正错误：</p>

\[w_{t+1} \leftarrow w_t + y_{n(t)}x_{n(t)}\]

    <p>\(w\): 代表分类线的法向量
\(x_n\): 是原点到 \(x_n\) 的向量</p>

    <p><img src="/assets/ml_base_2_1.png" alt="ml_base_2_1" /></p>
  </li>
</ol>

<ul>
  <li>当 \(y_n = +1\), 将 \(w\) 的方向向样本 \((x_n, y_n)\) 的方向转动。</li>
  <li>当 \(y_n = -1\), 将\(w\)的方向向样本 \((x_n, y_n)\) 的反方向转动。</li>
  <li>当不再出现错误的时候，训练结束。</li>
</ul>

<p><strong>PLA算法要能终止，要求训练数据集必须是线性可分的</strong></p>

<p><strong>\(w_t\) 越来越接近 \(w_f\)</strong></p>

<ul>
  <li>
    <p>\(w_f\): 目标函数 f 对应的参数，因此对于任意一个样本，它都能正确的分类：</p>

\[y_{n(t)}w^T_fx_{n(t)} \ge \min_ny_nw^T_fx_n \gt 0\]
  </li>
  <li>
    <p>衡量两个向量是否接近，可以用它们的内积，如果内积越小代表它们越不接近，相互垂直时为 0</p>

\[\begin{align}
\begin{split}
w_f^Tw_{t+1} &amp;= w_f^T(w_t+y_{n(t)}x_{n(t)}) \\
&amp;\ge w_f^Tw_t + \min_ny_nw_f^Tx_n \\
&amp;\gt w_f^Tw_t + 0
\end{split}
\end{align}\]
  </li>
</ul>

<p><strong>\(w_t\) 的增长速率不快</strong></p>

<p>\(w_t\)每次的更新不超过离分割线最远的样本的距离</p>

<ul>
  <li>\(w_t\) 的每次更新发生在有错误的时候：</li>
</ul>

<p>[sign(w_t^fx_{n(t)}) \neq y_{n(t)} \Leftrightarrow y_{n(t)}w_t^Tx_{n(t)} \leq 0]</p>

<ul>
  <li>对于每一次更新后的结果：</li>
</ul>

<table>
  <tbody>
    <tr>
      <td>[\begin{equation}\begin{split}</td>
      <td> </td>
      <td>w_{t+1}</td>
      <td> </td>
      <td>^2 &amp;=</td>
      <td> </td>
      <td>w_t + y_{n(t)}x_{n(t)}</td>
      <td> </td>
      <td>^2\\</td>
    </tr>
    <tr>
      <td>&amp;=</td>
      <td> </td>
      <td>w_t</td>
      <td> </td>
      <td>^2 + 2y_{n(t)}w_t^Tx_{n(t)} +</td>
      <td> </td>
      <td>y_{n(t)}x_{n(t)}</td>
      <td> </td>
      <td>^2\\</td>
    </tr>
    <tr>
      <td>&amp;\le</td>
      <td> </td>
      <td>w_t</td>
      <td> </td>
      <td>^2 + 0 +</td>
      <td> </td>
      <td>y_{n(t)x_{n(t)}}</td>
      <td> </td>
      <td>^2\\</td>
    </tr>
    <tr>
      <td>&amp;\le</td>
      <td> </td>
      <td>w_t</td>
      <td> </td>
      <td>^2 + \max_n</td>
      <td> </td>
      <td>y_{n(t)}x_{n(t)}</td>
      <td> </td>
      <td>^2\end{split}\end{equation}]</td>
    </tr>
  </tbody>
</table>

<p>其中  \(\max_n \Vert y_{n(t)}x_{n(t)} \Vert ^2\)  就代表了距离到分隔线最远的点的距离。</p>

<p>[\begin{equation}\begin{split}
   \text{start from w_0 = 0, after T mistake corrections,} \</p>

<p>\frac{w_f^T}{\Vert w_f \Vert} \frac{w_T}{\Vert w_T \Vert} \ge \sqrt T * \text{constant}</p>

<p>\end{split}\end{equation}]</p>

<p>\(w_f^Tw_{t+1}\) 的内积是小于等于1的，再根据上面的式子，知道T不可能为无穷大，所以运算会终止。</p>

<h2 id="pocket-算法">Pocket 算法</h2>
<p><strong>算法步骤</strong></p>

<ol>
  <li>随机初始化 w</li>
  <li>进行 t 轮的学习， t = 0, 1, …</li>
  <li>如果发生错误，按照 PLA 算法对 w进行纠正：\(w_{t+1} \leftarrow w_t + y_{n(t)}x_{n(t)}\)</li>
  <li>判断对比纠正后的算法与之前算法的错误率，如果更好，者保留新的w<sub>t+1</sub>, 否者保留之前的w。</li>
  <li>运算足够多次之后停止运算。</li>
</ol>

<p>Pocket算法是PLA的改进算法，用于解决<strong>线性不可分</strong>的数据集。
Pocket算法的运算量大：对于比PLA，在得到新的w<sub>t+1</sub>， 需要将所有数据集运算一遍，来获得错误率。</p>
:ET